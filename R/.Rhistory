function(j) cutoff_res(beta_hat[,i], X_train,
y_train, cutoff_can[j])[[1]]))
cut_sel[i, 1] = cutoff_out[which.min(cutoff_out[,2]), 1]
cut_sel[i, 2] = cutoff_out[tail(which(cutoff_out[,3] >= 0.5), n = 1), 1]
cut_sel[i, 3] = cutoff_out[which.max(cutoff_out[,5]), 1]
}
for (i in 1:4){
cutoff_out = t(sapply(1:length(cutoff_can),
function(j) cutoff_res(beta_hat[,i], X_train,
y_train, cutoff_can[j])[[1]]))
cut_sel[i, 1] = cutoff_out[which.min(cutoff_out[,2]), 1]
cut_sel[i, 2] = cutoff_out[tail(which(cutoff_out[,3] >= 0.5), n = 1), 1]
cut_sel[i, 3] = cutoff_out[which.max(cutoff_out[,5]), 1]
}
matrix(t(sapply(1:4, function(i) cutoff_res(beta_hat[,i], X_test,
y_test, cut_sel[i, 1])[[1]])),
nrow = 4,
dimnames =list(model_names, c("cutoff","error rate","sensitivity",
"specificity","f1 score")))
getwd()
wsdata0 = read.csv('Wholesale.csv')
wsdata1 = wsdata0[,3:8]
mydata = scale(wsdata1)
# Determine number of clusters
wss = (nrow(mydata)-1)*sum(apply(mydata,2,var))   # total SS
bigK = 20
for (i in 2:bigK) wss[i] = sum(kmeans(mydata, centers=i)$withinss)   # for k=2:K, compute within SS
plot(1:bigK, wss, type="b", xlab="Number of Clusters (k)",   ylab="Within-Group Sum of Squares")
title("Looking for elbow....")
mydata
head(mydata)
wss
nrow(mydata)
(nrow(mydata)-1)*sum(apply(mydata,2,var))   # total SS
sum(apply(mydata,2,var)
)
sum(apply(mydata,2,var))
(nrow(mydata)-1)*sum(apply(mydata,2,var))   # total SS
wss
wss = (nrow(mydata)-1)*sum(apply(mydata,2,var))   # total SS
wss
for (i in 2:bigK) wss[i] = sum(kmeans(mydata, centers=i)$withinss)   # for k=2:K, compute within SS
wss
plot(1:bigK, wss, type="b", xlab="Number of Clusters (k)",   ylab="Within-Group Sum of Squares")
title("Looking for elbow....")
kmeans(mydata, 5)$size
# let us fix k=5
#fit = kmeans(mydata, 5) # 5 cluster solution
kmeans(mydata, 5)$size
#> fit$size
#[1]  98   1  10 279  52
#fit = kmeans(mydata, 4) # 4 cluster solution
kmeans(mydata, 4)$size
#> fit$size
#[1] 328  43  68   1
#fit = kmeans(mydata, 3) # 3 cluster solution
kmeans(mydata, 3)$size
#> fit$size
#[1]  49  44 347
fit = kmeans(mydata,3)
# let us fix k=5
#fit = kmeans(mydata, 5) # 5 cluster solution
kmeans(mydata, 5)$size
#> fit$size
#[1]  98   1  10 279  52
#fit = kmeans(mydata, 4) # 4 cluster solution
kmeans(mydata, 4)$size
#> fit$size
#[1] 328  43  68   1
#fit = kmeans(mydata, 3) # 3 cluster solution
kmeans(mydata, 3)$size
#> fit$size
#[1]  49  44 347
fit = kmeans(mydata,3)
aggregate(mydata,by=list(fit$cluster),FUN=mean)  # get cluster means
kmclust.output = data.frame(mydata, fit$cluster)  # append cluster assignment
# Cluster Plot against 1st 2 principal components
library(cluster)
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
fit$cluster
mydata
kmclust.output
aggregate(mydata,by=list(fit$cluster),FUN=mean)  # get cluster means
aggregate(mydata,by=list(fit$cluster),FUN=mean)  # get cluster means
kmclust.output = data.frame(mydata, fit$cluster)  # append cluster assignment
# Cluster Plot against 1st 2 principal components
library(cluster)
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)
d <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(d, method="complete")
plot(fit) # display dendogram
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=3, border="red")
groups <- cutree(fit, k=3) # cut tree into 5 clusters
table(groups)
#groups
#  1   2   3
#429  10   1
# looks weird. then let us use ward method
fit <- hclust(d, method="ward")
plot(fit) # display dendogram
# draw dendogram with red borders around the 5 clusters
rect.hclust(fit, k=3, border="red")
groups <- cutree(fit, k=3) # cut tree into 5 clusters
table(groups)
clusplot(mydata, groups, color=TRUE, shade=TRUE, labels=2, lines=0)
library(mclust)
fit = Mclust(mydata)
plot(fit) # plot results
library(mclust)
fit = Mclust(mydata)
library(mclust)
fit = Mclust(mydata)
plot(fit) # plot results
library(mclust)
fit = Mclust(mydata)
plot(fit) # plot results
library(mclust)
fit = Mclust(mydata)
plot(fit) # plot results
summary(fit)
summary(fit)
clusplot(mydata, fit$classification, color=TRUE, shade=TRUE, labels=2, lines=0)
fit3 = Mclust(mydata, G=3)
summary(fit3) # display the 3-component model
#Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 3 components:
#
# log.likelihood   n df      BIC       ICL
#      -1526.219 440 83 -3557.64 -3593.981
#
#Clustering table:
#  1   2   3
#189 210  41
clusplot(mydata, fit3$classification, color=TRUE, shade=TRUE, labels=2, lines=0)
getwd()
library(rpar)
library(rpart)
buytest = read.table('buytest.txt', header = T)
buytest[buytest$SEX == "", 'SEX'] = NA
levels(buytest$SEX)[1] = NA
buytest[buytest$ORGSRC == "", 'ORGSRC'] = NA
levels(buytest$ORGSRC)[1] = NA
buydata = buytest[,-c(1, 10,19:26)] # 사용되지 않는 변수 제거
buydata = buydata[complete.cases(buydata),] # 결측치 제거
buydata = model.matrix(~., buydata)[,-1] # 가변수 생성
set.seed(1)
train_ind = sample(1:nrow(buydata), nrow(buydata)*0.7)
train = as.data.frame(buydata[train_ind,])
test = as.data.frame(buydata[-train_ind,])
X_train = buydata[train_ind, -1]
y_train = buydata[train_ind, 1]
X_test = buydata[-train_ind, -1]
y_test = buydata[-train_ind, 1]
library(rpart)
tree.buydata = rpart(as.factor(RESPOND)~., data = train)
tree.buydata
train
tree.buydata = rpart(as.factor(RESPOND)~., data = train,
control = rpart.control(cp = 0.005))
tree.buydata
plot(tree.buydata)
text(tree.buydata, cex = 0.8)
plot(tree.buydata, margin = 0.1)
text(tree.buydata, cex = 0.7, use.n =T)
tree.buydata = rpart(as.factor(RESPOND)~., data = train, control = rpart.control(cp = 0.001))
printcp(tree.buydata)
set.seed(1)
K = 10
sample.ind = sample(1:K, size = nrow(train), replace = T)
cp = seq(from = 0.001, to = 0.01, length = 30)
error = matrix(0, nrow = length(cp), K)
for (i in 1:length(cp)){
for (j in 1:K){
tmp = rpart(as.factor(RESPOND)~., data = train[sample.ind != j,], cp = cp[i])
error[i,j] = sum(predict(tmp, train[sample.ind == j,], type = "class")
!= train[sample.ind == j,]$RESPOND)/sum(sample.ind == j)
}
}
rowMeans(error)
rowMeans(error)
cp[which.min(rowMeans(error))]
rm(list=ls())
buytest = read.table('buytest.txt', header = T)
buytest[buytest$SEX == "", 'SEX'] = NA
levels(buytest$SEX)[1] = NA
buytest[buytest$ORGSRC == "", 'ORGSRC'] = NA
levels(buytest$ORGSRC)[1] = NA
buydata = buytest[,-c(1, 10,19:26)] # 사용되지 않는 변수 제거
buydata = buydata[complete.cases(buydata),] # 결측치 제거
buydata = model.matrix(~., buydata)[,-1] # 가변수 생성
set.seed(1)
train_ind = sample(1:nrow(buydata), nrow(buydata)*0.7)
train = as.data.frame(buydata[train_ind,])
test = as.data.frame(buydata[-train_ind,])
X_train = buydata[train_ind, -1]
y_train = buydata[train_ind, 1]
X_test = buydata[-train_ind, -1]
y_test = buydata[-train_ind, 1]
library(randomForest)
## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.
set.seed(1)
p = dim(as.matrix(train))[2] - 1
bag.fit = randomForest(x= X_train, y = as.factor(y_train),
mtry = p, ntree = 500, importance = T)
bag.fit
bag.fit
train
ncol(train) - 1
dim(as.matrix(train))[2] - 1
bag.fit
bag.fit
mean(y_test != predict(bag.fit, X_test))
varImpPlot(bag.fit)
importance(bag.fit)
set.seed(1)
rf.fit = randomForest(x= X_train, y = as.factor(y_train),
mtry = floor(sqrt(p)), ntree = 500, importance = T)
## mtry = floor(sqrt(p))가 바뀌는 부분
rf.fit
rf.fit
mean(y_test != predict(rf.fit, X_test))
varImpPlot(rf.fit)
importance(rf.fit)
buytest = read.table('buytest.txt', header = T)
buytest[buytest$SEX == "", 'SEX'] = NA
levels(buytest$SEX)[1] = NA
buytest[buytest$ORGSRC == "", 'ORGSRC'] = NA
levels(buytest$ORGSRC)[1] = NA
buydata = buytest[,-c(1, 10,19:26)] # 사용되지 않는 변수 제거
buydata = buydata[complete.cases(buydata),] # 결측치 제거
buydata = model.matrix(~., buydata)[,-1] # 가변수 생성
set.seed(1)
train_ind = sample(1:nrow(buydata), nrow(buydata)*0.7)
train = as.data.frame(buydata[train_ind,])
test = as.data.frame(buydata[-train_ind,])
X_train = buydata[train_ind, -1]
y_train = buydata[train_ind, 1]
X_test = buydata[-train_ind, -1]
y_test = buydata[-train_ind, 1]
train
library(xgboost)
install.packages('xgboost')
library(xgboost)
boost.fit = xgboost(data = X_train, label = y_train, max.depth = 2,
eta = 0.1, nround = 2, objective = "binary:logistic")
pred = predict(boost.fit, X_test)
mean(y_test != round(pred))
library(xgboost)
boost.fit = xgboost(data = X_train, label = y_train, max.depth = 2,
eta = 0.1, nround = 2, objective = "binary:logistic")
pred = predict(boost.fit, X_test)
mean(y_test != round(pred))
set.seed(123)
val.ind = sample(1:nrow(X_train), size = floor(nrow(X_train)*0.3))
val.err = c()
candidates = seq(from = 50, to = 250, by = 20)
for (i in candidates){
boost.val = xgboost(data = X_train[-val.ind,], label = y_train[-val.ind], max.depth = 2,
eta = 0.1, nround = i, objective = "binary:logistic", verbose = 0)
pred.val = predict(boost.val, X_train[val.ind,])
val.err = c(val.err, mean(y_train[val.ind] != round(pred.val)))
}
val.err
which.min(val.err)
boost.fit = xgboost(data = X_train, label = y_train, max.depth = 2,
eta = 0.1, nround = candidates[which.min(val.err)], objective = "binary:logistic", pred = predict(boost.fit, X_test))
mean(y_test != round(pred))
boost.fit = xgboost(data = X_train, label = y_train, max.depth = 2,
eta = 0.1, nround = candidates[which.min(val.err)], objective = "binary:logistic")
pred = predict(boost.fit, X_test)
mean(y_test != round(pred))
boost.fit = xgboost(data = X_train, label = y_train, max.depth = 2,
eta = 0.1, nround = candidates[which.min(val.err)], objective = "binary:logistic")
pred = predict(boost.fit, X_test)
mean(y_test != round(pred))
andidates[which.min(val.err)]
candidates[which.min(val.err)]
pred = predict(boost.fit, X_test)
mean(y_test != round(pred))
import_mat = xgb.importance(colnames(X_train), model = boost.fit)
print(import_mat)
library(Ckmeans.1d.dp)
install.packages('Ckmeans.1d.dp')
library(Ckmeans.1d.dp)
xgb.plot.importance(importance_matrix = import_mat)
roc.plot = function(pred_prob, y, model_name = NULL){
AUC = performance(prediction(pred_prob , y) , "auc")
ROC = performance(prediction(pred_prob ,y) , "tpr","fpr")
plot(ROC , main = paste(model_name,"\n AUC:",
round(as.numeric(AUC@y.values),4)),
col = "blue", lwd = 2.5)
abline(c(0,0), c(1,1), lty = 2, lwd = 2)
}
pred_probs_test = sapply(1:4, function(i) 1/(1+exp(-cbind(1, X_test)%*%beta_hat[,i])))
buytest = read.table('buytest.txt', header = T)
buytest[buytest$SEX == "", 'SEX'] = NA
levels(buytest$SEX)[1] = NA
buytest[buytest$ORGSRC == "", 'ORGSRC'] = NA
levels(buytest$ORGSRC)[1] = NA
buydata = buytest[,-c(1, 10,19:26)] # 사용되지 않는 변수 제거
buydata = buydata[complete.cases(buydata),] # 결측치 제거
buydata = model.matrix(~., buydata)[,-1] # 가변수 생성
set.seed(1)
train_ind = sample(1:nrow(buydata), nrow(buydata)*0.7)
train = as.data.frame(buydata[train_ind,])
test = as.data.frame(buydata[-train_ind,])
X_train = buydata[train_ind, -1]
y_train = buydata[train_ind, 1]
X_test = buydata[-train_ind, -1]
y_test = buydata[-train_ind, 1]
train
n1 = sum(y_train == 1)
set.seed(6)
cc_ind = sample(1:sum(y_train == 0),
size = 2*n1, replace = F)
cc_data = rbind(train[y_train == 1,],
train[y_train == 0,][cc_ind,])
cc_data = cc_data[sample(1:nrow(cc_data), nrow(cc_data), replace = F),]
table(cc_data$RESPOND)
dim(cc_data)
tol_iter = 50
beta_list = list()
set.seed(6)
for (iter in 1:tol_iter){
cc_ind = sample(1:sum(y_train == 0),
size = 2*n1, replace = F)
cc_data = rbind(train[y_train == 1,],
train[y_train == 0,][cc_ind,])
beta_list[[iter]] = coef(glm(RESPOND~., data = cc_data, family = 'binomial'))
}
train_pred_probs = sapply(1:tol_iter,
function(iter) 1/(1+exp(-cbind(1, X_train)%*%
beta_list[[iter]])))
train_pred_prob = rowMeans(train_pred_probs)
test_pred_probs = sapply(1:tol_iter,
function(iter) 1/(1+exp(-cbind(1, X_test)%*%
beta_list[[iter]])))
test_pred_prob = rowMeans(test_pred_probs)
beta_list
as.dataframe(beta_list)
as.DataFrame(beta_list)
as.Dataframe(beta_list)
as.data.frame(beta_list)
as.data.frame(beta_list, header = NULL)
as.data.frame(beta_list, header = NA)
as.data.frame(beta_list, col.names = NULL)
T(as.data.frame(beta_list))
t(as.data.frame(beta_list))
as.data.frame(t(beta_list))
beta_list
beta_list[1:5]
auc_res(newx = X_train, newy = y_train, pred_prob = train_pred_prob)
?auc_res
bus = read.csv('d:/bus_data.csv')
bus
library(deplyr)
library(dplyr)
bus %>% group_by(start) %>% group_by(end)
bus %>% group_by(start) %>% tally()
bus %>% group_by(start) %>% summarize()
bus %>% group_by(start) %>% summarize(sum)
bus %>% group_by(start)
bus %>% group_by(start) %>% summarize()
bus %>% group_by(start) %>% summarize(mean)
bus %>% group_by(start) %>% summarize(mean())
bus %>% group_by(start) %>% select(X6r)
bus %>% group_by(start) %>% select(X6r) %>% summarize(sum)
bus %>% group_by(start) %>% select(X6r) %>% summarize(sum())
bus %>% group_by(start) %>% select(X6r)
bus %>% group_by(start) %>% select(X6r) %>% summarize(sum(X6r))
bus %>% group_by(start) %>% select(X6r, X7r, X8r, X9r) %>% summarize(sum(X6r)) %>%
bus %>% group_by(start) %>% select(X6r, X7r, X8r, X9r) %>% summarize(sum(X6r))
bus %>% group_by(start) %>% select(X6r, X7r, X8r, X9r) %>% summarize(sum(X6r))
bus %>% group_by(start) %>% select(X6r, X7r, X8r, X9r) %>% summarize(sum(X6r), sum(X7r))
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r))
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange()
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange(sum(X6r))
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange()
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange(2)
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange()
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange('sum(X6r)')
bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r)) %>% arrange()
bus %>% group_by(start) %>% summarize(sum(X6r)) %>% arrange()
bus_start = bus %>% group_by(start) %>% summarize(sum(X6r), sum(X7r), sum(X8r), sum(X9r))
bus_start
bus_start %>% arange(sum(X6r))
arrange(bus_start, sum(X6r))
colnames(bus_start)
colnames(bus_start) = c('start', 'r6', 'r7', 'r8', 'r9')
bus_start %>% arrange(r6)
bus_start %>% arrange(desc(r6))
bus_start %>% arrange(desc(r7))
bus_start %>% arrange(desc(r8))
bus_start %>% arrange(desc(r9))
bus_start %>% arrange(desc(r6)) %>% select(start)[1:10]
bus_start %>% arrange(desc(r6)) %>% select(start)
loc_data = bus_start %>% arrange(desc(r6)) %>% select(start)
loc_data
cbind(loc_data, bus_start %>% arrange(desc(r7)) %>% select(start))
loc_data
loc_data = cbind(loc_data, bus_start %>% arrange(desc(r7)) %>% select(start))
loc_data = cbind(loc_data, bus_start %>% arrange(desc(r8)) %>% select(start))
loc_data
loc_data = cbind(loc_data, bus_start %>% arrange(desc(r9)) %>% select(start))
loc_data
colnames(loc_data) = c('6r', '7r', '8r', '9r')
loc_data
loc_data[1:10,]
read.csv('d:/bus_set.csv')
read.csv('d:/bus_set.csv')
bus_setread.csv('d:/bus_set.csv')
bus_set = read.csv('d:/bus_set.csv')
bus_set %>% group_by(loc)
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set %>% group_by(loc) %>% summarize(sum(Go)) %>% arrange(desc)
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set = read.csv('d:/bus_set.csv')
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set = read.csv('d:/bus_set.csv')
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set = read.csv('d:/bus_set.csv')
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set
bus_set = read.csv('d:/bus_set.csv')
bus_set %>% group_by(loc) %>% summarize(sum(Go))
bus_set %>% group_by(loc) %>% summarize(sum(Go), sum(Exchange))
bus_test = bus_set %>% group_by(loc) %>% summarize(sum(Go), sum(Exchange))
colnames(bus_test) = c('loc', 'go', 'ex')
arrange(bus_test,desc(go))
arrange(bus_test,desc(ex))
arrange(bus_test,desc(go))
bust_ready = arrange(bus_test,desc(go))
bus_ready = arrange(bus_test,desc(go))
bus_ready$loc
split(bus_ready$loc)
split(bus_ready$loc[1])
bus_ready$loc
split(bus_ready$loc, ' ')
split(bus_ready$loc, delimeter = ' ')
bus_ready$loc
strsplit(bus_ready$loc)
strsplit(bus_ready$loc,' ')
?strsplit
str_split(bus_ready$loc,' ')
strsplit(bus_ready$loc,' ')
strsplit(bus_ready$loc[1],' ')
bus_ready$loc[1]
strsplit(as.character(bus_ready$loc),' ')
strsplit(as.character(bus_ready$loc),' ')[[:]][1][2]
strsplit(as.character(bus_ready$loc),' ')[1][2]
strsplit(as.character(bus_ready$loc),' ')[1]
strsplit(as.character(bus_ready$loc),' ')[2]
strsplit(as.character(bus_ready$loc),' ')[1][2]
strsplit(as.character(bus_ready$loc),' ')[1]
unclass(strsplit(as.character(bus_ready$loc),' ')[1])
unclass(strsplit(as.character(bus_ready$loc),' '))
levels(unclass(strsplit(as.character(bus_ready$loc),' ')))
strsplit(as.character(bus_ready$loc),' ')
as.data.frame(strsplit(as.character(bus_ready$loc),' '))
?as.data.frame
as.matrix(strsplit(as.character(bus_ready$loc),' '))
strsplit(as.character(bus_ready$loc),' ')
strsplit(as.character(bus_ready$loc),' ')[[,2]]
strsplit(as.character(bus_ready$loc),' ')[[:,2]]
strsplit(as.character(bus_ready$loc),' ')[[1]]
strsplit(as.character(bus_ready$loc),' ')[[1]][2]
new_loc
for (i in length(bus_ready$loc)){new_loc = strsplit(as.character(bus_ready$loc),' ')[[i]][2]}
new_loc
for (i in length(bus_ready$loc)){new_loc[i] = strsplit(as.character(bus_ready$loc),' ')[[i]][2]}
new_loc
length(bus_ready$loc)
print(i)}
for (i in length(bus_ready$loc)){
new_loc[i] = strsplit(as.character(bus_ready$loc),' ')[[i]][2]
print(i)
}
for (i in 1:length(bus_ready$loc)){
new_loc[i] = strsplit(as.character(bus_ready$loc),' ')[[i]][2]
}
new_loc
cbind(bus_ready, new_loc)
bus_ready = cbind(bus_ready, new_loc)
bus_ready %>% group_by(new_loc) %>% summarize(sum(go), sum(ex))
bus_ready %>% group_by(new_loc) %>% summarize(go = sum(go), ex = sum(ex))
bus_ready %>% group_by(new_loc) %>% summarize(go = sum(go), ex = sum(ex)) %>% arrange(desc(go))
bus_ready
install.packages('mlogit')
library(mlogit)
ydata = read.csv('./yogurt100.csv')
ydata[,15:18]=ydata[,15:18]*10  # scaling up prices of yogdata
attach(ydata)
ydata$Choice = Brand.1*1+Brand.2*2+Brand.3*3+Brand.4*4
detach(ydata)
ydata2 = mlogit.data(ydata, choice ="Choice", shape = "wide", varying=11:18, alt.levels=1:4)
ydata
ydata2
mlout = mlogit(Choice~Price+Feature, data=ydata2)
summary(mlout)
attach(ydata)
ydata$Choice = Brand.1*1+Brand.2*2+Brand.3*3+Brand.4*4
detach(ydata)
ydata2 = mlogit.data(ydata, choice ="Choice", shape = "wide", varying=11:18, alt.levels=1:4)
ydata2
mpout = mlogit(Choice~Price+Feature, data=ydata2, probit=T)
summary(mpout)
bus_sub = bus_ready %>% group_by(new_loc) %>% summarize(go = sum(go), ex = sum(ex)) %>% arrange(desc(go))
bus_sub
write.csv(bus_ready[1:3], 'bus_동.csv')
write.csv(bus_sub, 'bus_시.csv')
getwd()
