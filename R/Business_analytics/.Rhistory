v.set <- rdata[2001:4000,] # 테스트셋 2001~4000
v.set2 <- rdata[2001:4000, 2:7] # ID 제거
rm(list=ls())
#####기본 설정#####
library(dplyr)
library(glmnet)
rdata=read.csv('./database_marketing/hw2/mailorder.csv')
str(rdata)
rdata[ ,2] <- as.numeric(rdata[,2]) # gender값 숫자로 변경
rdata[ ,2] <- rdata[,2]-1 # gender값에 -1 (1이 남성, 0이 여성)
rdata[ ,2] <- as.factor(rdata[,2]) # gender 값 factor로 변경 (차이는 없엉)
t.set <- rdata[1:2000,] # 훈련셋 1~2000
t.set2 <- rdata[1:2000, 2:7] # ID 제거
v.set <- rdata[2001:4000,] # 테스트셋 2001~4000
v.set2 <- rdata[2001:4000, 2:7] # ID 제거
###########변수 수정용 코드3 : Duration 및 frequency 값 루트 씌운 후 각 해당 변수를 나누어 변수 생성##################
t.transaction_month = sqrt(t.set2$frequency / t.set2$duration) #훈련셋-월 주문 횟수
t.spending_month = sqrt(t.set2$monetary / t.set2$duration) #훈련셋-월 주문액
t.spending_transaction = sqrt(t.set2$monetary / t.set2$frequency) #훈련셋-1회 구매액
v.transaction_month = sqrt(v.set2$frequency / v.set2$duration) #테스트셋-월 주문 횟수
v.spending_month = sqrt(v.set2$monetary / v.set2$duration) #테스트셋-월 주문액
v.spending_transaction = sqrt(v.set2$monetary / v.set2$frequency) #테스트셋-1회 구매액
t.set3 = cbind(t.set2 ,t.transaction_month, t.spending_month, t.spending_transaction) # 훈련셋에 생성한 변수 추가
v.set3 = cbind(v.set2 ,v.transaction_month, v.spending_month, v.spending_transaction) # 테스트셋에 생성한 변수 추가
##########변수 수정(sqrt)시 단순 선형3-1##############
lm.fit = lm(purchase ~ ., data = t.set3) # 추가변수 모두 투입하여 회귀
lm.fit2 = lm(purchase ~ 1, data = t.set3) # 절편생성 (전진선택용)
for.fit=step(lm.fit2, direction = 'forward', scope = list(lower=lm.fit2, upper=lm.fit)) # 전진선택 변수 투입하여 회귀 (셋다 같음)
both.fit=step(lm.fit) # 양측 선택 변수 투입하여 회귀 (셋다 같음)
back.fit=step(lm.fit, direction = 'backward') # 후진 선택 변수 투입하여 회귀 (셋다 같음)
pred.data=predict(for.fit, newdata = v.set3, type="response")  # 예측값 생성
#pred.data2=predict(both.fit, newdata = v.set3, type="response")
#pred.data3=predict(back.fit, newdata = v.set3, type="response")
v.set3[10] <- pred.data # 예측력 18.2%
#View(a)
a=arrange(v.set3, desc(V10))
sum(a[1:500, 6])/500
anova(for.fit) # F값 t.spending_transaction 유의확률 15%라 아슬하지 대체로 적합
summary(for.fit) # T값 전부 95% 이내 유의함
#-# 예측력: 18.2%
#-# 유효변수: gender, frequency, recency, t.transaction_month, t.spending_transaction, t.spending_month
rm(list=ls())
library(xlsx)
library(rgl)
library(dplyr)
Sys.setlocale(,'Korean')
mailorder = read.xlsx2('d:/github/r/database_marketing/hw2/mailorder.xls', 1)
## Factor > numericd
mailorder$monetary = as.numeric(as.character(mailorder$monetary)) #총 지출액
mailorder$recency = as.numeric(as.character(mailorder$recency)) #최근 구매
mailorder$transaction = as.numeric(as.character(mailorder$frequency)) #총 구매 건수
mailorder$duration = as.numeric(as.character(mailorder$duration)) #첫 구매
mailorder$purchase = as.numeric(as.character(mailorder$purchase)) #메일구매여부
mailorder = mailorder[,-5]
transaction_month = mailorder$transaction / mailorder$duration #월 주문 횟수
#spending_month = mailorder$monetary / mailorder$duration #월 주문액
#spending_transaction = mailorder$monetary / mailorder$transaction #1회 구매액
mailorder = cbind(mailorder,transaction_month)
#mailorder = cbind(mailorder,spending_month, transaction_month, spending_transaction)
test_group1 = mailorder[1:2000,]
valid_group1 = mailorder[2001:4000,]
summary(mailorder)
#test1 = step(lm(purchase~.-id, data = test_group1))
test1 = lm(purchase~gender+recency+transaction+transaction_month, data = test_group1)
valid1 = predict(test1, newdata = valid_group1, type = "response")
valid1_sum = summary(sort(valid1)[1501:2000])
test1_result = rep(1,2000)
test1_result[valid1<valid1_sum[1]] = 0
#summary(test1) anova(test1)
a = table(test1_result, valid_group1$purchase)
cat('\n맞출 확률 = ')
cat(a[2,2]/sum(a[2,]))
#####기본 설정#####
library(dplyr)
library(glmnet)
rdata=read.csv('./database_marketing/hw2/mailorder.csv')
str(rdata)
rdata[ ,2] <- as.numeric(rdata[,2]) # gender값 숫자로 변경
rdata[ ,2] <- rdata[,2]-1 # gender값에 -1 (1이 남성, 0이 여성)
rdata[ ,2] <- as.factor(rdata[,2]) # gender 값 factor로 변경 (차이는 없엉)
t.set <- rdata[1:2000,] # 훈련셋 1~2000
t.set2 <- rdata[1:2000, 2:7] # ID 제거
v.set <- rdata[2001:4000,] # 테스트셋 2001~4000
v.set2 <- rdata[2001:4000, 2:7] # ID 제거
##############기본 변수 단순 선형 1-1############
fit.data=lm(purchase~., data=t.set2) # 모든 변수 투입
fit.data2=lm(purchase~1, data=t.set2) # 절편값만 생성(전진선택용)
step(fit.data, direction = 'backward') # 후진
step(fit.data2, direction = 'forward', scope = list(lower=fit.data2, upper=fit.data)) # 전진
step(fit.data, direction = 'both', scope=list(upper=fit.data)) # 둘다
fit.final=lm(purchase~recency+frequency+gender, data=t.set2) # 선택 변수 동일하여 해당과 같이 회귀식 작성
summary(fit.final)
pred.data=predict(fit.final, newdata = v.set2, type="response") # test 데이터 기준 예측데이터 생성
v.set2[7] <- pred.data # test 셋에 예측 데이터 열 추가
a=arrange(v.set2, desc(V7)) # 예측 값 순서대로 내림차순 정렬
sum(a[1:500, 6])/500 # 예측 값 상위 500위까지 카운트하여 예측력 계산 / 예측력: 18.2%
anova(fit.final) # F값 확인 - F값 전부 1% 미만
summary(fit.final) # P값 확인 - P값 전부 1% 미만
#-# 예측력: 18.2%
#-# 유효변수: gender, frequency, recency
########### 기본 변수 LASSO 1-2##############
x=model.matrix(purchase~.,t.set2)[,-1] # LASSO 적용을 위한 훈련셋의 x 매트릭스 생성
x2=model.matrix(purchase~.,v.set2)[,-1] # 테스트셋 적용을 위한 테스트셋의 x 매트릭스 생성
y=t.set2$purchase # LASSO 적용을 위한 훈련셋의 y 매트릭스 생성
grid=seq(0,0.036,length=5000) # 임의의 람다 값 설정(시행착오 통해 람다 값 범위 설정)
lasso.mod=glmnet(x,y,alpha=1,lambda=grid, family = 'binomial') # LASSO 시행
plot(lasso.mod)
set.seed(1) # 랜덤값 고정
cv.out=cv.glmnet(x,y, family='binomial', type.measure='auc') # 교차검증 수행
plot(cv.out)
bestlam=cv.out$lambda.min # 검정오차 가장 낮은 값(최적 람다) 출력
lasso.pred=predict(lasso.mod, s=bestlam, newx = x2, type='response') # 예측 셋
getwd()
setwd('./marketing_analysis')
setwd('./marketing_analytics
')
setwd('./marketing_analytics')
getwd()
setwd('../business_analytics')
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
plot(y)
r = 2
y1 = runif(1000, -r, r)
y2 = sample(c(-1,1),100, replace = T) * sqrt(1-y1^2)
y = cbind(y1, y2)
plot(y)
r = 2
y1 = runif(1000, -r, r)
y2 = sample(c(-1,1),100, replace = T) * sqrt(1-y1^2)
y = cbind(y1, y2)
z = rbind(x,y)
ploy(z)
z = rbind(x,y)
plot(z)
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
r = 2
y1 = runif(1000, -r, r)
y2 = sample(c(-1,1),100, replace = T) * sqrt(1-y1^2)
y = cbind(y1, y2)
z = rbind(x,y)
plot(z)
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
r = 3
y1 = runif(1000, -r, r)
y2 = sample(c(-1,1),100, replace = T) * sqrt(1-y1^2)
y = cbind(y1, y2)
z = rbind(x,y)
plot(z)
set.seed(10)
x1 = runif(100, -1.5, 1.5)
x2 = sample(c(-1,1),100, replace = T) * sqrt(1-x1^2)
x = cbind(x1,x2)
x
r = 2
y1 = runif(1000, -r, r)
y2 = sample(c(-1,1),100, replace = T) * sqrt(1-y1^2)
y = cbind(y1, y2)
z = rbind(x,y)
plot(z)
load("D:/Github/R/Business_analytics/tot.RData")
load("D:/Github/R/Business_analytics/tot.RData")
dim(tot)
dim(tot)
head(tot)
names(tot)
head(tot)
library(KoNLP)
library(httr)
library(rvest)
library(dplyr)
#Sys.getlocale()
Sys.setlocale("LC_ALL", "Korean")
client_id = 'pNeL9M2Busi7vWn4XkW6';
client_secret = 'nTY9Mj5v2K';
header = httr::add_headers(
'X-Naver-Client-Id' = client_id,
'X-Naver-Client-Secret' = client_secret)
query.n = query = '유플'
# encoding 변화
query = iconv(query, to = 'UTF-8', toRaw = T)
# iconv(query, to = "UTF-8", toRaw = F)
query = paste0('%', paste(unlist(query), collapse = '%'))
query = toupper(query)
end_num = 1000
display_num = 100
start_point = seq(1, end_num, by = display_num)
i = 1
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=date')
url_body = read_xml(GET(url, header))
title = url_body %>% xml_nodes('item title') %>%
xml_text()
bloggername = url_body %>%
xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>%
xml_text()
link = url_body %>% xml_nodes('item link') %>%
xml_text()
description = url_body %>% xml_nodes('item description') %>%
html_text()
final_dat = NULL
for(i in 1:length(start_point))
{
# request xml format
url = paste0('https://openapi.naver.com/v1/search/blog.xml?query=',query,'&display=',display_num,'&start=',start_point[i],'&sort=sim')
#option header
url_body = read_xml(GET(url, header), encoding = "UTF-8")
title = url_body %>% xml_nodes('item title') %>% xml_text()
bloggername = url_body %>% xml_nodes('item bloggername') %>% xml_text()
postdate = url_body %>% xml_nodes('postdate') %>% xml_text()
link = url_body %>% xml_nodes('item link') %>% xml_text()
description = url_body %>% xml_nodes('item description') %>% html_text()
temp_dat = cbind(title, bloggername, postdate, link, description)
final_dat = rbind(final_dat, temp_dat)
cat(i, '\n')
}
final_dat = data.frame(final_dat, stringsAsFactors = F)
# 상위 블로거 검색
#library(dplyr)
tb = final_dat %>% select(bloggername) %>% table()
top_blogger = sort(tb, decreasing = T)[1:4]
tmp = final_dat %>% select(bloggername, title, link) %>% filter(bloggername %in% names(top_blogger))
#검색량 분ㅍ
library(pspline)
tb = final_dat %>% select(postdate) %>% table()
x <-as.Date(names(tb), format = "%Y%m%d")
y <- as.numeric(tb)
# as.Date("2019[02[03", format = '%Y[%m[%d')
fit <- sm.spline(x = as.integer(x), y = y, cv = TRUE)
plot(x, y, pch = 19, cex = 0.5)
lines(x=x, y=fit$ysmth, lty = 2, col = 'blue')
#기간 동안 검색량 분석 02
xx <- as.Date(min(x):max(x),origin = "1970-01-01")
yy = rep(0, length(xx))
yy[xx%in%x] = y
fit<-sm.spline(xx,yy,cv = TRUE)
plot(xx, yy, pch = 19, cex = 0.5)
points(fit$x, fit$ysmth, type = 'l', lty = 2, lwd = 1.5, col = 'blue')
#국소다항회귀 (local polynomial regression)
xint = as.integer(xx)
rdata = data.frame(y = yy, x = xint)
fit<-loess(y~x,data = rdata, span = 0.5, normalize = FALSE)
plot(fit, pch = 19, cex = 0.5)
points(fit$x,fit$fitted, type = 'l', lty = 2, lwd = 1.5, col = 'blue')
#Span 값에 따라 주변(%) 데이터를 참조 (i.e. k-means)
#fit<-loess(y~x,data = rdata, span = 0.1, normalize = FALSE)
#plot(fit, pch = 19, cex = 0.5)
#points(fit$x,fit$fitted, type = 'l', lty = 2, lwd = 1.5, col = 'blue')
# K fold cross validation
k.fold = 5
idx <-sample(1:5, length(xint), replace = TRUE)
k = 1
rdata.tr <- rdata[idx != k, ]
rdata.va <- rdata[idx == k, ]
fit<-loess(y~x,data = rdata.tr, span = 0.1, normalize = FALSE)
fit.y<-predict(fit, newdata = rdata.va)
mean((fit.y-rdata.va$y)^2, na.rm = T)
# K fold cross validation 2 - loop
k.fold = 5
idx <-sample(1:k.fold, length(xint), replace = TRUE)
span.var <- seq(0.02, 0.5, by  = 0.01)
valid.mat <- NULL
for (j in 1:length(span.var))
{
valid.err <- c()
for (k in 1:k.fold)
{
rdata.tr <- rdata[idx != k, ]
rdata.va <- rdata[idx == k, ]
fit<-loess(y~x,data = rdata.tr,
span = span.var[j], normalize = FALSE)
fit.y<-predict(fit, newdata = rdata.va)
valid.err[k] <- mean((fit.y-rdata.va$y)^2, na.rm = T)
}
valid.mat <- cbind(valid.mat, valid.err)
}
load("D:/Github/R/Business_analytics/tot.RData")
dim(tot)
x = t(tot)
rownames(x)
dim(tot)
x = t(tot)
names = rownames(x)
rownames(x) = colnames(x) = NULL
x = x[,1:3000]
x
x = t(tot)
names = rownames(x)
rownames(x) = colnames(x) = NULL
x = x[,1:3000]
x
head(x)
head(x[:,1:10])
head(x[,1:10])
head(tot[,1:10])
head(t(tot[,1:10]))
head(tot[,1:10])
tot[1:6,1:10]
t(tot[1:6,1:10])
t(tot[:6,:10])
t(tot[1:6,1:10])
kmx = kmeans(x, centers = 4)
kmx
dim(x)
max(x)
min(x)
dist.E = dist(x)
cmds = cmdscale(dist.E, k=2)  # k 는 차원 수(2)
head(cmds)
plot(cmds, colors = kmx$cluster)
kmx$cluster
plot(cmds, pch = 19, colors = kmx$cluster)
plot(cmds, pch = 19, col = kmx$cluster)
names
strsplit(names, split = ' ')
topnames
strsplit(names, split = ' ' )[1]
strsplit(names, split = ' ' )[:][1]
strsplit(names, split = ' ' )[,][1]
strsplit(names, split = ' ' )[[1]]
strsplit(names, split = ' ' )[[1]][1]
strsplit(names, split = ' ' )[[:]][1]
strsplit(names, split = ' ' )[[*]][1]
for(i in names){strsplit(i, split = ' ' )[1]}
[for(i in names){strsplit(i, split = ' ' )[1]}]
for(i in names)[{strsplit(i, split = ' ' )[1]}]
topnames= list()
n=1
for(i in names){
topnames[n] = strsplit(i, split = ' ' )[1]
n = n+1
}
topnames
print(i)
}
for(i in names){
print(i)
}
for(i in names){
print(strsplit(i, split = ' ' )[1])
}
for(i in names){
print(strsplit(i, split = ' ' )[[1]][1])
}
topnames= list()
n=1
for(i in names){
topnames[n] = strsplit(i, split = ' ' )[[1]][1]
n = n+1
}
topnames
unclass(topnames)
topnames= list()
n=1
for(i in names){
topnames = topnames + strsplit(i, split = ' ' )[[1]][1]
n = n+1
}
topnames= list()
n=1
for(i in names){
topnames = topnames + strsplit(i, split = ' ' )[[1]][1]
n = n+1
}
topnames= list()
n=1
for(i in names){
topnames.append( strsplit(i, split = ' ' )[[1]][1]))
topnames= list()
n=1
for(i in names){
topnames.append( strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
topnames= list()
n=1
for(i in names){
topnames.append( strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
topnames= list()
n=1
for(i in names){
append(topnames, strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
topnames
topnames= list()
n=1
for(i in names){
append(strsplit(i, split = ' ' )[[1]][1], topnames)
n = n+1
}
topnames
topnames= list()
n=1
for(i in names){
topnames = topnames + list(strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
for(i in names){
print(list(strsplit(i, split = ' ' )[[1]][1]))
print(list(strsplit(i, split = ' ' )[[1]][1]))}
for(i in names){
print(list(strsplit(i, split = ' ' )[[1]][1]))}
for(i in names){
cat(list(strsplit(i, split = ' ' )[[1]][1]))}
for(i in names){
print(strsplit(i, split = ' ' )[[1]][1])
}
for(i in names){
strsplit(i, split = ' ' )[[1]][1]
}
for(i in names){
topnames = topnames + strsplit(i, split = ' ' )[[1]][1]
}
a = list()
a + 'avc'
topnames= c()
n=1
for(i in names){
topnames = topnames + list(strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
topnames= list()
n=1
for(i in names){
topnames[n] = list(strsplit(i, split = ' ' )[[1]][1])
n = n+1
}
topnames
rownames(x)
rownames(x) = topnames
x
x[1:6][1:10]
x[[1:6][1:10]]
x[1:6,1:10]
library(dplyr)
cbind(x, rownames(x))
x1 = cbind(x, rownames(x))
x1 %>% sort_by([,3001])
x1[,3001]
x1%>% group_by([,3001])
x1%>% group_by([3001])
x1%>% group_by('3001')
x1%>% group_by(x1[,3001])
colnames(x1)
colnames(x1) = range(3001)
colnames(x1) = range(1:3001)
dim(x1)
range(1:3001)
colnames(x1) = 1:3001
x %>% group_by('3001')
x1 %>% group_by('3001')
x1 %>% group_by(3001)
data.frame(x1) %>% group_by(3001)
x1 = data.frame(x1)
x1%>% group_by(3001) %>% sum()
as.numeric(x1)
x1[1]
x1%>% group_by(3001) %>% count()
x1%>% group_by(3001)
x1[1:6,3002]
x1[1:6,3001]
x1%>% group_by(3001) %>% tally()
x1%>% group_by('3001') %>% tally()
colnames(x1)
x1%>% group_by('x3001') %>% tally()
x1%>% group_by('x3001')
x1%>% group_by('x3001') %>% summarise(n = n())
x1['x3001']
x1[,'x3001']
x1$'x3001'
x1$x3001
table(topnames)
topnames
unique(topnames)
x1 = cbind(rownames(x),x)
colnames(x1) = 1:3001
x1 = data.frame(x1)
x1[1:6,1:10]
x1 = data.frame(x1, stringsAsFactors = F)
x1[1:6,1:10]
x1%>% group_by('x1') %>% summarise(n = n())
x1%>% group_by(x1) %>% summarise(n = n())
x1[1:6,1:10]
colnames(x1) = 1:3001
x1[1:6,1:10]
x1%>% group_by(x1) %>% summarise(n = n())
x1%>% group_by(1) %>% summarise(n = n())
x1%>% group_by('1') %>% summarise(n = n())
