```{r}
buytest = read.table('buytest.txt', header = T)

buytest[buytest$SEX == "", 'SEX'] = NA
levels(buytest$SEX)[1] = NA
buytest[buytest$ORGSRC == "", 'ORGSRC'] = NA
levels(buytest$ORGSRC)[1] = NA

buydata = buytest[,-c(1, 10,19:26)] # 사용되지 않는 변수 제거
buydata = buydata[complete.cases(buydata),] # 결측치 제거
buydata = model.matrix(~., buydata)[,-1] # 가변수 생성

set.seed(1)
train_ind = sample(1:nrow(buydata), nrow(buydata)*0.7)
train = as.data.frame(buydata[train_ind,])
test = as.data.frame(buydata[-train_ind,])

X_train = buydata[train_ind, -1]
y_train = buydata[train_ind, 1]
X_test = buydata[-train_ind, -1]
y_test = buydata[-train_ind, 1]
```

```{r}
null = glm(RESPOND~1, data = train, family = 'binomial')
full = glm(RESPOND~., data = train, family = 'binomial')
forward = step(null, scope = list(lower = null, upper = full), data = train, direction = "forward")
summary(forward)
```

```{r}
library(glmnet)
```

```{r}
ridge.fit = glmnet(X_train, as.factor(y_train), alpha = 0, family="binomial" )
ridge.fit$lambda[c(1, 10, 100)]

ridge.fit$beta[,c(1, 10, 100)]
```

```{r}
set.seed(1)
cv.ridge = cv.glmnet(X_train, as.factor(y_train), alpha = 0, family = "binomial")
bestlam = cv.ridge$lambda.min
ridge.fit = glmnet(X_train, as.factor(y_train), alpha = 0, lambda = bestlam, family = "binomial")
ridge.fit$beta
```



### 라쏘
```{r}
lasso.fit = glmnet(X_train, as.factor(y_train), alpha = 1, family="binomial")
lasso.fit$lambda[c(1, 5, 10)]
lasso.fit$beta[,c(1, 5, 10)]
```

```{r}
set.seed(1)
cv.lasso = cv.glmnet(X_train, as.factor(y_train), alpha = 1, family="binomial")
bestlam = cv.lasso$lambda.min
lasso.fit = glmnet(X_train, as.factor(y_train), alpha = 1, lambda = bestlam, family="binomial")
lasso.fit$beta
```



### 비교

```{r}
logit = glm(RESPOND~., data = train, family = "binomial")

beta_hat = logit$coefficients
#------------------------------------
# forward selection
#------------------------------------
tmp = forward$coefficients
beta_forward = c()
for (i in 1:length(beta_hat)){
if (names(beta_hat)[i] %in% names(tmp)) beta_forward[i] = tmp[names(beta_hat)[i]]
else beta_forward[i] = 0
}
beta_hat = cbind(beta_hat, beta_forward)
#------------------------------------
# Ridge & LASSO
#------------------------------------
beta_hat = cbind(beta_hat, c(ridge.fit$a0, as.vector(ridge.fit$beta)),
c(lasso.fit$a0, as.vector(lasso.fit$beta)))

```

```{r}
library(ROCR)
auc_res = function(beta = NULL, newx, newy, pred_prob = NULL){
if (!is.null(beta)){
X = cbind(1,as.matrix(newx))
pred_prob = 1/(1+exp(-X%*%beta)) }
AUC = performance(prediction(pred_prob , newy) , "auc")
return(AUC@y.values[[1]])
}
auc_table = rbind(sapply(1:4, function(i) auc_res(beta_hat[,i], X_train, y_train)),
sapply(1:4, function(i) auc_res(beta_hat[,i], X_test, y_test)))
rownames(auc_table) = c('Training set', 'Test set')
colnames(auc_table) = model_names = c('Logistic','Logistic+AIC', 'Ridge', 'LASSO')
auc_table
```

```{r}
cutoff_res = function(beta_hat = NULL, newx, response, cutoff, pred_prob = NULL){
if (!is.null(beta_hat)) {
  X = cbind(1,as.matrix(newx))
  pred_prob = 1/(1+exp(-X%*%beta_hat))}
pred = ifelse(pred_prob> cutoff, 1, 0)
error_rate = mean(response != pred)
sensitivity = sum(response == 1 & pred == 1)/sum(response == 1)
specificity = sum(response == 0 & pred == 0)/sum(response == 0)
precision = sum(response == 1 & pred == 1)/sum(pred == 1)
recall = sensitivity
if (sum(response == 1 & pred == 1) == 0) {f1 = 0}
else {f1 = 2*(precision*recall)/(precision+recall)}
cross_table = table(response, pred)
return(list(res = c(cutoff, round(error_rate,4),
                  round(sensitivity,4), round(specificity,4), round(f1, 4)),
            cross_table = cross_table))
}
```

```{r}
cut_sel = matrix(0, nrow = 4, ncol = 3)
cutoff_can = seq(0.01, 0.99, by = 0.01)
for (i in 1:4){
cutoff_out = t(sapply(1:length(cutoff_can),
function(j) cutoff_res(beta_hat[,i], X_train,
y_train, cutoff_can[j])[[1]]))
cut_sel[i, 1] = cutoff_out[which.min(cutoff_out[,2]), 1]
cut_sel[i, 2] = cutoff_out[tail(which(cutoff_out[,3] >= 0.5), n = 1), 1]
cut_sel[i, 3] = cutoff_out[which.max(cutoff_out[,5]), 1]
}
matrix(t(sapply(1:4, function(i) cutoff_res(beta_hat[,i], X_test,
y_test, cut_sel[i, 1])[[1]])),
nrow = 4,
dimnames =list(model_names, c("cutoff","error rate","sensitivity",
"specificity","f1 score")))
```

