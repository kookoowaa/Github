```{r}

wsdata0 = read.csv('Wholesale.csv')
wsdata1 = wsdata0[,3:8]
mydata = scale(wsdata1)
head(mydata)
```

```{r}
# Determine number of clusters
wss = (nrow(mydata)-1)*sum(apply(mydata,2,var))   # total SS
bigK = 20
for (i in 2:bigK) wss[i] = sum(kmeans(mydata, centers=i)$withinss)   # for k=2:K, compute within SS
plot(1:bigK, wss, type="b", xlab="Number of Clusters (k)",   ylab="Within-Group Sum of Squares")
title("Looking for elbow....")

```

```{r}
# let us fix k=5
#fit = kmeans(mydata, 5) # 5 cluster solution
kmeans(mydata, 5)$size
#> fit$size
#[1]  98   1  10 279  52
#fit = kmeans(mydata, 4) # 4 cluster solution
kmeans(mydata, 4)$size
#> fit$size
#[1] 328  43  68   1
#fit = kmeans(mydata, 3) # 3 cluster solution
kmeans(mydata, 3)$size
#> fit$size
#[1]  49  44 347   
fit = kmeans(mydata,3)
```

```{r}
aggregate(mydata,by=list(fit$cluster),FUN=mean)  # get cluster means 
kmclust.output = data.frame(mydata, fit$cluster)  # append cluster assignment

# Cluster Plot against 1st 2 principal components
library(cluster) 
clusplot(mydata, fit$cluster, color=TRUE, shade=TRUE, labels=2, lines=0)

```


#########################

> Heirarchical clustering  

##########################
```{r}
d <- dist(mydata, method = "euclidean") # distance matrix
fit <- hclust(d, method="complete") 
plot(fit) # display dendogram
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit, k=3, border="red")
groups <- cutree(fit, k=3) # cut tree into 5 clusters
table(groups)
#groups
#  1   2   3 
#429  10   1 
# looks weird. then let us use ward method
```

```{r}
fit <- hclust(d, method="ward") 
plot(fit) # display dendogram
# draw dendogram with red borders around the 5 clusters 
rect.hclust(fit, k=3, border="red")
groups <- cutree(fit, k=3) # cut tree into 5 clusters
table(groups)
clusplot(mydata, groups, color=TRUE, shade=TRUE, labels=2, lines=0)
```

```{r}
library(mclust)
fit = Mclust(mydata)
plot(fit) # plot results 
```

```{r}
summary(fit)
clusplot(mydata, fit$classification, color=TRUE, shade=TRUE, labels=2, lines=0)
```

```{r}
fit3 = Mclust(mydata, G=3)
summary(fit3) # display the 3-component model
#Mclust VVV (ellipsoidal, varying volume, shape, and orientation) model with 3 components:
#
# log.likelihood   n df      BIC       ICL
#      -1526.219 440 83 -3557.64 -3593.981
#
#Clustering table:
#  1   2   3 
#189 210  41 
clusplot(mydata, fit3$classification, color=TRUE, shade=TRUE, labels=2, lines=0)
```