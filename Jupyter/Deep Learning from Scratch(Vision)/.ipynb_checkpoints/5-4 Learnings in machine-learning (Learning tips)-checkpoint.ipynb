{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *학습 관련 기술들*\n",
    "\n",
    "## 4. 바른 학습을 위해\n",
    "\n",
    "- 기계학습에서는 오버피팅이 문제가 되는 경우가 많으며, 이를 억제하는 기술이 중요\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) 오버피팅\n",
    "- 오버피팅은 주로 다음 두 경우에 발생\n",
    "> - 매개변수가 많고 표현력이 높은 모델\n",
    "> - 훈련 데이터가 적은 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 의도적으로 오버피팅을 발생시키기 위해 훈련 데이터를 300/60,000개 사용하고 7층 네트워크를 사용\n",
    "- 각 층 뉴런은 100개, 활성화 함수는 ReLU 사용, 학습 방법은 Adam 시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from data.mnist import load_mnist\n",
    "from data.multi_layer_net import MultiLayerNet\n",
    "from data.optimizer import SGD\n",
    "from data.optimizer import Adam\n",
    "from data.optimizer import AdaGrad\n",
    "from data.trainer import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원하는 데이터만 추출 (1~300번)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True)\n",
    "\n",
    "# 오버피팅을 재현하기 위해 학습 데이터 수를 줄임\n",
    "x_train = x_train[:300]\n",
    "t_train = t_train[:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 아래와 같이 기본 세팅 설정 (network구성, weight decay, 학습방법 설정, batch/epochs 구성 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight decay（가중치 감쇠） 설정 =======================\n",
    "weight_decay_lambda = 0 # weight decay를 사용하지 않을 경우\n",
    "#weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10)\n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_epochs까지 for문 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.09, test acc:0.1057\n",
      "epoch:10, train acc:0.38333333333333336, test acc:0.2858\n",
      "epoch:20, train acc:0.51, test acc:0.3732\n",
      "epoch:30, train acc:0.7566666666666667, test acc:0.5631\n",
      "epoch:40, train acc:0.84, test acc:0.6549\n",
      "epoch:50, train acc:0.8766666666666667, test acc:0.6826\n",
      "epoch:60, train acc:0.9033333333333333, test acc:0.7031\n",
      "epoch:70, train acc:0.9433333333333334, test acc:0.7185\n",
      "epoch:80, train acc:0.9666666666666667, test acc:0.7179\n",
      "epoch:90, train acc:0.9866666666666667, test acc:0.7321\n",
      "epoch:100, train acc:0.9966666666666667, test acc:0.7369\n",
      "epoch:110, train acc:0.9966666666666667, test acc:0.7415\n",
      "epoch:120, train acc:1.0, test acc:0.7432\n",
      "epoch:130, train acc:1.0, test acc:0.7481\n",
      "epoch:140, train acc:1.0, test acc:0.7495\n",
      "epoch:150, train acc:1.0, test acc:0.7499\n",
      "epoch:160, train acc:1.0, test acc:0.7546\n",
      "epoch:170, train acc:1.0, test acc:0.7526\n",
      "epoch:180, train acc:1.0, test acc:0.7514\n",
      "epoch:190, train acc:1.0, test acc:0.753\n",
      "epoch:200, train acc:1.0, test acc:0.7548\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        if i % (iter_per_epoch*10) == 0:\n",
    "            print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14fdda3f5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위의 그래프에서 볼 수 있듯이 train 데이터에서의 정확도가 100에폭부터 거의 100%에 근사하는 반면, test데이터에서의 정확도간에 큰 오차 발생\n",
    "- 위같은 사례를 오버피팅이라고 볼 수 있음\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) 가중치 감소\n",
    "\n",
    "- 오버피팅 방지를 위해 **weight decay(가중치 감소)**가 가장 빈번하게 사용됨\n",
    "\n",
    "- 오버피팅은 가중치 매개변수의 값이 커서 발생하는 경우가 많기 때문에 큰 가중치에 상응하는 패널티를 부과하여 오버피팅 억제를 시도 (panelty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Recap\n",
    "> - 신경망 학습의 목적은 손실함수 값 최소화\n",
    "- 따라서 가중치의 L2 norm(제곱 norm)을 손실함수에 더하며 가중치가 커지느 것을 억제 가능\n",
    "- L2 norm에 따른 가중치 감소는 $\\frac{1}{2}\\lambda W^2$가 됨\n",
    "- 여기서 $\\lambda$는 하이퍼파라미터로 패널티 규모를 설정, 앞쪽의 $\\frac{1}{2}$는 미분 결과인 $\\lambda W$를 조정하는 역할의 상수\n",
    "- 가중치 감소는 모든 가중치의 손실함수에 $\\frac{1}{2}\\lambda W^2$를 더하며, 기울기 계산 시 정규화 항을 미분한 $\\lambda W$를 더함\n",
    "___\n",
    "- $W = (w_1, w_2, w_3, ... , w_n)$일 때\n",
    "- L2 norm $= \\sqrt{w_1^2 + w_2^2 + w_3^2 + ... + w_n^2}$ 이며,\n",
    "- L1 norm $ = \\lvert w_1^2 \\rvert + \\lvert w_2^2 \\rvert + \\lvert w_3^2 \\rvert + ... +\\lvert w_n^2 \\rvert$ 로 표현 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 실험에서 weight decay를 적용하여 $\\lambda = 0.1$로 재실험하면 아래와 같은 결과 기대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight decay（가중치 감쇠） 설정 =======================\n",
    "#weight_decay_lambda = 0 # weight decay를 사용하지 않을 경우\n",
    "weight_decay_lambda = 0.1\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNet(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100], output_size=10,\n",
    "                        weight_decay_lambda=weight_decay_lambda)\n",
    "optimizer = SGD(lr=0.01) # 학습률이 0.01인 SGD로 매개변수 갱신\n",
    "\n",
    "max_epochs = 201\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "epoch_cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, train acc:0.15333333333333332, test acc:0.1076\n",
      "epoch:10, train acc:0.34, test acc:0.2143\n",
      "epoch:20, train acc:0.5066666666666667, test acc:0.3568\n",
      "epoch:30, train acc:0.5766666666666667, test acc:0.4238\n",
      "epoch:40, train acc:0.6433333333333333, test acc:0.4916\n",
      "epoch:50, train acc:0.6966666666666667, test acc:0.5448\n",
      "epoch:60, train acc:0.8033333333333333, test acc:0.6111\n",
      "epoch:70, train acc:0.8266666666666667, test acc:0.6421\n",
      "epoch:80, train acc:0.85, test acc:0.6713\n",
      "epoch:90, train acc:0.8566666666666667, test acc:0.6781\n",
      "epoch:100, train acc:0.8733333333333333, test acc:0.6958\n",
      "epoch:110, train acc:0.9033333333333333, test acc:0.7029\n",
      "epoch:120, train acc:0.8933333333333333, test acc:0.7056\n",
      "epoch:130, train acc:0.89, test acc:0.7117\n",
      "epoch:140, train acc:0.9, test acc:0.7223\n",
      "epoch:150, train acc:0.9133333333333333, test acc:0.7298\n",
      "epoch:160, train acc:0.93, test acc:0.7317\n",
      "epoch:170, train acc:0.9266666666666666, test acc:0.7234\n",
      "epoch:180, train acc:0.9233333333333333, test acc:0.7367\n",
      "epoch:190, train acc:0.93, test acc:0.7351\n",
      "epoch:200, train acc:0.9233333333333333, test acc:0.7328\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000000000):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grads = network.gradient(x_batch, t_batch)\n",
    "    optimizer.update(network.params, grads)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "        if i % (iter_per_epoch*10) == 0:\n",
    "            print(\"epoch:\" + str(epoch_cnt) + \", train acc:\" + str(train_acc) + \", test acc:\" + str(test_acc))\n",
    "\n",
    "        epoch_cnt += 1\n",
    "        if epoch_cnt >= max_epochs:\n",
    "            print('finish')\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14fdd259390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 주목할 점은 2가지 정도임\n",
    "> 1) training과 test set 결과 간의 오차율이 줄어듬\n",
    ">\n",
    "> 2) 전체적인 정확도가 100%에 도달하지 못함\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 드롭아웃\n",
    "\n",
    "- Weight decay 방식은 간단하게 구현 가능학고 지나친 학습을 억제할 수 있음\n",
    "- 하지만 신경망 모델이 복잡해질수록 가중치 감소만으로는 대응하기 어려워짐\n",
    "- 이때 사용 가능한 방식이 **drop out(드롭아웃)**이며, 뉴런을 임의로 삭제하면서 학습하는 방식임\n",
    "![](image/fig 6-22.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout:\n",
    "    def __init__(self, dropout_ratio = 0.5):\n",
    "        self.droupout_ratio = droupout_ratio\n",
    "        self.mask = None\n",
    "    \n",
    "    \n",
    "    def forward(self, x, train_flg = True):\n",
    "        if train_flg:\n",
    "            self.mask = np.random.rand(*x.shape) > self.dropout_ratio\n",
    "            return x * self.mask\n",
    "        else:\n",
    "            return x * (1 - self.dropout_ratio)\n",
    "    \n",
    "    \n",
    "    def backward(self, dout):\n",
    "        return dout * self.mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- self.mask에서 x와 형상이 같은 $N(0,1)$배열을 무작위로 생성하고 그 값이 dropout_ratio보다 큰 원소만 True로 설정\n",
    "- 역전파때에도 마찬가지로 순전파 때 통과시킨 뉴런만 신호를 통과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.trainer import Trainer\n",
    "from data.multi_layer_net_extend import MultiLayerNetExtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.28163311973376\n",
      "=== epoch:1, train acc:0.16, test acc:0.1569 ===\n",
      "train loss:2.29288194527247\n",
      "train loss:2.3039861237645685\n",
      "train loss:2.2838216934298776\n",
      "=== epoch:2, train acc:0.16666666666666666, test acc:0.1586 ===\n",
      "train loss:2.276608398487763\n",
      "train loss:2.2884841764398023\n",
      "train loss:2.2659067073331944\n",
      "=== epoch:3, train acc:0.17333333333333334, test acc:0.1631 ===\n",
      "train loss:2.2894632546146987\n",
      "train loss:2.2720651687977225\n",
      "train loss:2.28098284036297\n",
      "=== epoch:4, train acc:0.17333333333333334, test acc:0.1639 ===\n",
      "train loss:2.290352595075366\n",
      "train loss:2.286517771194532\n",
      "train loss:2.302293150397212\n",
      "=== epoch:5, train acc:0.17333333333333334, test acc:0.1668 ===\n",
      "train loss:2.297776030228622\n",
      "train loss:2.2931662879667942\n",
      "train loss:2.2807370340601407\n",
      "=== epoch:6, train acc:0.18, test acc:0.1692 ===\n",
      "train loss:2.275454284511495\n",
      "train loss:2.2882898587316287\n",
      "train loss:2.291890829955229\n",
      "=== epoch:7, train acc:0.17333333333333334, test acc:0.1683 ===\n",
      "train loss:2.2968136924321767\n",
      "train loss:2.282635559973597\n",
      "train loss:2.2748256278086205\n",
      "=== epoch:8, train acc:0.18666666666666668, test acc:0.168 ===\n",
      "train loss:2.301117510907784\n",
      "train loss:2.2870843502420026\n",
      "train loss:2.271696545254954\n",
      "=== epoch:9, train acc:0.18333333333333332, test acc:0.1697 ===\n",
      "train loss:2.2672135703914877\n",
      "train loss:2.2734251607101874\n",
      "train loss:2.2683050934341136\n",
      "=== epoch:10, train acc:0.18333333333333332, test acc:0.1698 ===\n",
      "train loss:2.272356709237379\n",
      "train loss:2.286697042666692\n",
      "train loss:2.2631622569223917\n",
      "=== epoch:11, train acc:0.18666666666666668, test acc:0.1711 ===\n",
      "train loss:2.282187529270745\n",
      "train loss:2.286822812252569\n",
      "train loss:2.2819638035535337\n",
      "=== epoch:12, train acc:0.19, test acc:0.1732 ===\n",
      "train loss:2.2677352368577717\n",
      "train loss:2.262942854299674\n",
      "train loss:2.2750072704201543\n",
      "=== epoch:13, train acc:0.19, test acc:0.1752 ===\n",
      "train loss:2.2800444255591192\n",
      "train loss:2.2516851602372894\n",
      "train loss:2.2801453377113936\n",
      "=== epoch:14, train acc:0.2, test acc:0.1808 ===\n",
      "train loss:2.267839735792767\n",
      "train loss:2.286381865652717\n",
      "train loss:2.280768450791227\n",
      "=== epoch:15, train acc:0.21, test acc:0.1873 ===\n",
      "train loss:2.269900619538991\n",
      "train loss:2.2750644939637534\n",
      "train loss:2.2722111462078396\n",
      "=== epoch:16, train acc:0.21666666666666667, test acc:0.1925 ===\n",
      "train loss:2.2536660679547382\n",
      "train loss:2.2634655830981028\n",
      "train loss:2.266875575833464\n",
      "=== epoch:17, train acc:0.21666666666666667, test acc:0.1984 ===\n",
      "train loss:2.268991421460734\n",
      "train loss:2.2906730023651374\n",
      "train loss:2.261334466329343\n",
      "=== epoch:18, train acc:0.21666666666666667, test acc:0.2064 ===\n",
      "train loss:2.270330924797357\n",
      "train loss:2.256700229028256\n",
      "train loss:2.2607674352485736\n",
      "=== epoch:19, train acc:0.23666666666666666, test acc:0.2107 ===\n",
      "train loss:2.262212255977471\n",
      "train loss:2.2701360022214514\n",
      "train loss:2.263287617279468\n",
      "=== epoch:20, train acc:0.24, test acc:0.2149 ===\n",
      "train loss:2.255733791734222\n",
      "train loss:2.2473530079484805\n",
      "train loss:2.276392854270605\n",
      "=== epoch:21, train acc:0.24333333333333335, test acc:0.2197 ===\n",
      "train loss:2.2643690563070193\n",
      "train loss:2.2644489831859405\n",
      "train loss:2.266617282469815\n",
      "=== epoch:22, train acc:0.24666666666666667, test acc:0.2222 ===\n",
      "train loss:2.253709912735995\n",
      "train loss:2.2795733245093626\n",
      "train loss:2.2624949225079227\n",
      "=== epoch:23, train acc:0.25333333333333335, test acc:0.2294 ===\n",
      "train loss:2.2605368441272544\n",
      "train loss:2.281106180060851\n",
      "train loss:2.2511923017925133\n",
      "=== epoch:24, train acc:0.2633333333333333, test acc:0.2319 ===\n",
      "train loss:2.2456737848551827\n",
      "train loss:2.2567614520181896\n",
      "train loss:2.265425549386062\n",
      "=== epoch:25, train acc:0.2633333333333333, test acc:0.2345 ===\n",
      "train loss:2.2575845776960044\n",
      "train loss:2.246362888045941\n",
      "train loss:2.252537145816495\n",
      "=== epoch:26, train acc:0.26, test acc:0.2331 ===\n",
      "train loss:2.262330984620505\n",
      "train loss:2.255938120429142\n",
      "train loss:2.2691313564436215\n",
      "=== epoch:27, train acc:0.25, test acc:0.2358 ===\n",
      "train loss:2.219556544774986\n",
      "train loss:2.254816489667423\n",
      "train loss:2.239182495479413\n",
      "=== epoch:28, train acc:0.25666666666666665, test acc:0.2358 ===\n",
      "train loss:2.24745917937347\n",
      "train loss:2.2585877203221543\n",
      "train loss:2.267257955700531\n",
      "=== epoch:29, train acc:0.2633333333333333, test acc:0.2388 ===\n",
      "train loss:2.2758958380684264\n",
      "train loss:2.264979982178419\n",
      "train loss:2.2471260397528385\n",
      "=== epoch:30, train acc:0.26666666666666666, test acc:0.2421 ===\n",
      "train loss:2.237996461817047\n",
      "train loss:2.26064568438413\n",
      "train loss:2.2440057850790236\n",
      "=== epoch:31, train acc:0.2633333333333333, test acc:0.2453 ===\n",
      "train loss:2.2391913240166805\n",
      "train loss:2.248221727396973\n",
      "train loss:2.237040599863547\n",
      "=== epoch:32, train acc:0.26, test acc:0.2445 ===\n",
      "train loss:2.2569590470172565\n",
      "train loss:2.2539583536999497\n",
      "train loss:2.25666574291409\n",
      "=== epoch:33, train acc:0.26, test acc:0.2497 ===\n",
      "train loss:2.2446075623844046\n",
      "train loss:2.236526153778404\n",
      "train loss:2.249171777947619\n",
      "=== epoch:34, train acc:0.28, test acc:0.254 ===\n",
      "train loss:2.2304226101534614\n",
      "train loss:2.237235965391613\n",
      "train loss:2.252252177917349\n",
      "=== epoch:35, train acc:0.29333333333333333, test acc:0.2593 ===\n",
      "train loss:2.249790643546968\n",
      "train loss:2.224345797261663\n",
      "train loss:2.231381103594872\n",
      "=== epoch:36, train acc:0.2866666666666667, test acc:0.2558 ===\n",
      "train loss:2.2313098878510433\n",
      "train loss:2.236669156724977\n",
      "train loss:2.2571708430584967\n",
      "=== epoch:37, train acc:0.2833333333333333, test acc:0.2574 ===\n",
      "train loss:2.2444585402179076\n",
      "train loss:2.224708020045691\n",
      "train loss:2.2329605278707043\n",
      "=== epoch:38, train acc:0.29, test acc:0.2557 ===\n",
      "train loss:2.22146954304158\n",
      "train loss:2.2493848338458142\n",
      "train loss:2.232740021750636\n",
      "=== epoch:39, train acc:0.30333333333333334, test acc:0.2602 ===\n",
      "train loss:2.2335897781070364\n",
      "train loss:2.2438766859820642\n",
      "train loss:2.2174224787977828\n",
      "=== epoch:40, train acc:0.31333333333333335, test acc:0.263 ===\n",
      "train loss:2.24124666003039\n",
      "train loss:2.237697002648275\n",
      "train loss:2.2156787840326\n",
      "=== epoch:41, train acc:0.2966666666666667, test acc:0.2606 ===\n",
      "train loss:2.2444280504820244\n",
      "train loss:2.2304422943435456\n",
      "train loss:2.2408486997897237\n",
      "=== epoch:42, train acc:0.30666666666666664, test acc:0.2661 ===\n",
      "train loss:2.23058344129785\n",
      "train loss:2.19722257385959\n",
      "train loss:2.2220573885369173\n",
      "=== epoch:43, train acc:0.3, test acc:0.2624 ===\n",
      "train loss:2.224907117240033\n",
      "train loss:2.2517511854211416\n",
      "train loss:2.2416230395158063\n",
      "=== epoch:44, train acc:0.29333333333333333, test acc:0.2628 ===\n",
      "train loss:2.247208005497847\n",
      "train loss:2.240940865947021\n",
      "train loss:2.235843604429897\n",
      "=== epoch:45, train acc:0.31, test acc:0.2696 ===\n",
      "train loss:2.2625040783403243\n",
      "train loss:2.2418360417224057\n",
      "train loss:2.2320030481654394\n",
      "=== epoch:46, train acc:0.32, test acc:0.27 ===\n",
      "train loss:2.2233394090679206\n",
      "train loss:2.231902362900782\n",
      "train loss:2.2418341043588494\n",
      "=== epoch:47, train acc:0.31666666666666665, test acc:0.27 ===\n",
      "train loss:2.2185127434651637\n",
      "train loss:2.228413496519797\n",
      "train loss:2.2425764041080334\n",
      "=== epoch:48, train acc:0.31666666666666665, test acc:0.2756 ===\n",
      "train loss:2.244242456514659\n",
      "train loss:2.2280189114445936\n",
      "train loss:2.211846275785183\n",
      "=== epoch:49, train acc:0.3233333333333333, test acc:0.28 ===\n",
      "train loss:2.212516049090163\n",
      "train loss:2.218225526772684\n",
      "train loss:2.2058376518493463\n",
      "=== epoch:50, train acc:0.31, test acc:0.2748 ===\n",
      "train loss:2.1956114147981647\n",
      "train loss:2.221084931374274\n",
      "train loss:2.2028776657596953\n",
      "=== epoch:51, train acc:0.31, test acc:0.2733 ===\n",
      "train loss:2.2200963145453425\n",
      "train loss:2.2416726898961654\n",
      "train loss:2.2029631604468487\n",
      "=== epoch:52, train acc:0.31, test acc:0.2761 ===\n",
      "train loss:2.2088317812544975\n",
      "train loss:2.2066706459018417\n",
      "train loss:2.2420707932743937\n",
      "=== epoch:53, train acc:0.31666666666666665, test acc:0.2732 ===\n",
      "train loss:2.217706642730151\n",
      "train loss:2.1855981439499215\n",
      "train loss:2.195178385668484\n",
      "=== epoch:54, train acc:0.31666666666666665, test acc:0.2685 ===\n",
      "train loss:2.172760857611176\n",
      "train loss:2.201933691679411\n",
      "train loss:2.1794476346999714\n",
      "=== epoch:55, train acc:0.30333333333333334, test acc:0.2635 ===\n",
      "train loss:2.202312135897976\n",
      "train loss:2.2307675405797456\n",
      "train loss:2.220562304163658\n",
      "=== epoch:56, train acc:0.2966666666666667, test acc:0.2636 ===\n",
      "train loss:2.2182976495763733\n",
      "train loss:2.216337328952872\n",
      "train loss:2.2027455838257946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:57, train acc:0.3, test acc:0.2638 ===\n",
      "train loss:2.2162317770034248\n",
      "train loss:2.2134151806972526\n",
      "train loss:2.1967698671288396\n",
      "=== epoch:58, train acc:0.31666666666666665, test acc:0.2759 ===\n",
      "train loss:2.197101142303516\n",
      "train loss:2.16478275186079\n",
      "train loss:2.1866392372864225\n",
      "=== epoch:59, train acc:0.31, test acc:0.2723 ===\n",
      "train loss:2.183957715156324\n",
      "train loss:2.1955221773431464\n",
      "train loss:2.1938404195104706\n",
      "=== epoch:60, train acc:0.30666666666666664, test acc:0.2662 ===\n",
      "train loss:2.175483270775972\n",
      "train loss:2.1976414927724215\n",
      "train loss:2.221481373921462\n",
      "=== epoch:61, train acc:0.3, test acc:0.2627 ===\n",
      "train loss:2.206603859342078\n",
      "train loss:2.176008090395337\n",
      "train loss:2.2196272659045384\n",
      "=== epoch:62, train acc:0.30666666666666664, test acc:0.2666 ===\n",
      "train loss:2.159807870248863\n",
      "train loss:2.20257758766022\n",
      "train loss:2.1772874957331334\n",
      "=== epoch:63, train acc:0.2966666666666667, test acc:0.2632 ===\n",
      "train loss:2.1632658628227897\n",
      "train loss:2.196642967167897\n",
      "train loss:2.1609437831675504\n",
      "=== epoch:64, train acc:0.29333333333333333, test acc:0.2603 ===\n",
      "train loss:2.212731883644496\n",
      "train loss:2.2121272498865863\n",
      "train loss:2.1763085547031173\n",
      "=== epoch:65, train acc:0.3, test acc:0.266 ===\n",
      "train loss:2.198723235706129\n",
      "train loss:2.1769655054541817\n",
      "train loss:2.190035833770283\n",
      "=== epoch:66, train acc:0.31, test acc:0.2698 ===\n",
      "train loss:2.2058952514582244\n",
      "train loss:2.1955389151647013\n",
      "train loss:2.1701745857380335\n",
      "=== epoch:67, train acc:0.3, test acc:0.2663 ===\n",
      "train loss:2.1666258717023354\n",
      "train loss:2.2049423898898612\n",
      "train loss:2.1640468238529453\n",
      "=== epoch:68, train acc:0.31333333333333335, test acc:0.2719 ===\n",
      "train loss:2.199957648322196\n",
      "train loss:2.1949023868374895\n",
      "train loss:2.147448466083696\n",
      "=== epoch:69, train acc:0.31666666666666665, test acc:0.2762 ===\n",
      "train loss:2.1617777736104937\n",
      "train loss:2.190147904592079\n",
      "train loss:2.194327576246907\n",
      "=== epoch:70, train acc:0.32, test acc:0.2739 ===\n",
      "train loss:2.204385212181692\n",
      "train loss:2.1856384067129255\n",
      "train loss:2.2169991190931473\n",
      "=== epoch:71, train acc:0.3433333333333333, test acc:0.2873 ===\n",
      "train loss:2.1776582786031153\n",
      "train loss:2.161954413947877\n",
      "train loss:2.1515098109127986\n",
      "=== epoch:72, train acc:0.34, test acc:0.2887 ===\n",
      "train loss:2.160472858959677\n",
      "train loss:2.200018516616694\n",
      "train loss:2.172598383592347\n",
      "=== epoch:73, train acc:0.35333333333333333, test acc:0.2927 ===\n",
      "train loss:2.1758214188023057\n",
      "train loss:2.1650062387621323\n",
      "train loss:2.1650291309445966\n",
      "=== epoch:74, train acc:0.36, test acc:0.2958 ===\n",
      "train loss:2.154163415727215\n",
      "train loss:2.1959719930699815\n",
      "train loss:2.1412865184770884\n",
      "=== epoch:75, train acc:0.35333333333333333, test acc:0.2933 ===\n",
      "train loss:2.2003650554738368\n",
      "train loss:2.1737574761049796\n",
      "train loss:2.143566778340775\n",
      "=== epoch:76, train acc:0.3566666666666667, test acc:0.2955 ===\n",
      "train loss:2.1573627861670635\n",
      "train loss:2.138757346953847\n",
      "train loss:2.1618371851174993\n",
      "=== epoch:77, train acc:0.3566666666666667, test acc:0.2966 ===\n",
      "train loss:2.195969762680158\n",
      "train loss:2.137454880097297\n",
      "train loss:2.1645699360702726\n",
      "=== epoch:78, train acc:0.3566666666666667, test acc:0.2987 ===\n",
      "train loss:2.1113693160999394\n",
      "train loss:2.133478442139509\n",
      "train loss:2.1167572446094938\n",
      "=== epoch:79, train acc:0.3466666666666667, test acc:0.2896 ===\n",
      "train loss:2.121171410234995\n",
      "train loss:2.125130242480132\n",
      "train loss:2.146248727572621\n",
      "=== epoch:80, train acc:0.3466666666666667, test acc:0.2896 ===\n",
      "train loss:2.1406000279019244\n",
      "train loss:2.154951970517339\n",
      "train loss:2.1446941099736865\n",
      "=== epoch:81, train acc:0.36, test acc:0.293 ===\n",
      "train loss:2.16602967228657\n",
      "train loss:2.102217044066439\n",
      "train loss:2.1406557688725956\n",
      "=== epoch:82, train acc:0.3466666666666667, test acc:0.2902 ===\n",
      "train loss:2.163755715628729\n",
      "train loss:2.1440020311410026\n",
      "train loss:2.1048929799267158\n",
      "=== epoch:83, train acc:0.36, test acc:0.2959 ===\n",
      "train loss:2.123736107164752\n",
      "train loss:2.1151672392296845\n",
      "train loss:2.083734693570021\n",
      "=== epoch:84, train acc:0.35, test acc:0.2965 ===\n",
      "train loss:2.125302450778823\n",
      "train loss:2.1547271989276924\n",
      "train loss:2.1280590330234834\n",
      "=== epoch:85, train acc:0.36, test acc:0.2976 ===\n",
      "train loss:2.161460948211817\n",
      "train loss:2.1462946789501003\n",
      "train loss:2.145330816263206\n",
      "=== epoch:86, train acc:0.36, test acc:0.3 ===\n",
      "train loss:2.1027260247756763\n",
      "train loss:2.0851317052947067\n",
      "train loss:2.1393158101889687\n",
      "=== epoch:87, train acc:0.3433333333333333, test acc:0.2922 ===\n",
      "train loss:2.1013758557770306\n",
      "train loss:2.120863547056858\n",
      "train loss:2.136059319865998\n",
      "=== epoch:88, train acc:0.3433333333333333, test acc:0.2936 ===\n",
      "train loss:2.1229692485952665\n",
      "train loss:2.1387850794924037\n",
      "train loss:2.081280023422698\n",
      "=== epoch:89, train acc:0.36333333333333334, test acc:0.2978 ===\n",
      "train loss:2.130685570533748\n",
      "train loss:2.121308787106227\n",
      "train loss:2.1257435960527418\n",
      "=== epoch:90, train acc:0.3466666666666667, test acc:0.2963 ===\n",
      "train loss:2.150422555923228\n",
      "train loss:2.090521554439966\n",
      "train loss:2.1292160616767397\n",
      "=== epoch:91, train acc:0.35333333333333333, test acc:0.301 ===\n",
      "train loss:2.122287575430845\n",
      "train loss:2.1415912845969145\n",
      "train loss:2.1490361442896515\n",
      "=== epoch:92, train acc:0.36, test acc:0.307 ===\n",
      "train loss:2.1158936964542545\n",
      "train loss:2.1335962098364623\n",
      "train loss:2.1213526109256327\n",
      "=== epoch:93, train acc:0.36333333333333334, test acc:0.3107 ===\n",
      "train loss:2.0892590439374796\n",
      "train loss:2.1222443524032046\n",
      "train loss:2.127793481377968\n",
      "=== epoch:94, train acc:0.36333333333333334, test acc:0.3116 ===\n",
      "train loss:2.1527077235578456\n",
      "train loss:2.083936708810577\n",
      "train loss:2.116531805999247\n",
      "=== epoch:95, train acc:0.37333333333333335, test acc:0.3171 ===\n",
      "train loss:2.0844219801901533\n",
      "train loss:2.0658890676387758\n",
      "train loss:2.0541506861260648\n",
      "=== epoch:96, train acc:0.38, test acc:0.3201 ===\n",
      "train loss:2.05539152927138\n",
      "train loss:2.1168139410714972\n",
      "train loss:2.0945264020652163\n",
      "=== epoch:97, train acc:0.37333333333333335, test acc:0.3164 ===\n",
      "train loss:2.082417001096981\n",
      "train loss:2.0136305056387096\n",
      "train loss:2.0638640875983345\n",
      "=== epoch:98, train acc:0.37333333333333335, test acc:0.3153 ===\n",
      "train loss:2.078390942979417\n",
      "train loss:2.112226065360419\n",
      "train loss:2.1212945142589605\n",
      "=== epoch:99, train acc:0.37333333333333335, test acc:0.3169 ===\n",
      "train loss:2.0764868261425473\n",
      "train loss:2.1075647527088903\n",
      "train loss:2.0729042356100624\n",
      "=== epoch:100, train acc:0.39, test acc:0.3199 ===\n",
      "train loss:2.016469510479251\n",
      "train loss:2.118177517757897\n",
      "train loss:2.067629714664072\n",
      "=== epoch:101, train acc:0.39, test acc:0.3211 ===\n",
      "train loss:2.073993720711854\n",
      "train loss:2.063663068182171\n",
      "train loss:2.0512716883133297\n",
      "=== epoch:102, train acc:0.3933333333333333, test acc:0.3227 ===\n",
      "train loss:2.0693481243018748\n",
      "train loss:2.027304880427571\n",
      "train loss:2.0736061106263937\n",
      "=== epoch:103, train acc:0.3933333333333333, test acc:0.3215 ===\n",
      "train loss:2.0554532906068115\n",
      "train loss:2.0082477507894976\n",
      "train loss:2.0481083971281433\n",
      "=== epoch:104, train acc:0.4, test acc:0.3205 ===\n",
      "train loss:2.0834541361347285\n",
      "train loss:2.1065091376913787\n",
      "train loss:2.048121149077115\n",
      "=== epoch:105, train acc:0.4066666666666667, test acc:0.3249 ===\n",
      "train loss:2.032941388405091\n",
      "train loss:2.0276215979170678\n",
      "train loss:2.031112313657312\n",
      "=== epoch:106, train acc:0.4066666666666667, test acc:0.3237 ===\n",
      "train loss:2.0324142012476996\n",
      "train loss:2.0876680539954604\n",
      "train loss:2.014412555916176\n",
      "=== epoch:107, train acc:0.4033333333333333, test acc:0.3239 ===\n",
      "train loss:2.057709907074288\n",
      "train loss:2.0791817092511407\n",
      "train loss:2.0775429997164974\n",
      "=== epoch:108, train acc:0.4, test acc:0.3286 ===\n",
      "train loss:2.065763385390368\n",
      "train loss:2.07135568814582\n",
      "train loss:2.048546449833042\n",
      "=== epoch:109, train acc:0.39666666666666667, test acc:0.3294 ===\n",
      "train loss:2.0167723487800364\n",
      "train loss:2.027879454484098\n",
      "train loss:2.085130678125055\n",
      "=== epoch:110, train acc:0.4033333333333333, test acc:0.3312 ===\n",
      "train loss:2.0126507498179094\n",
      "train loss:2.0597755089727383\n",
      "train loss:2.0817660758540955\n",
      "=== epoch:111, train acc:0.4033333333333333, test acc:0.3344 ===\n",
      "train loss:2.0448187522304235\n",
      "train loss:2.047651003574688\n",
      "train loss:1.9906408306474808\n",
      "=== epoch:112, train acc:0.4066666666666667, test acc:0.3338 ===\n",
      "train loss:2.0468275862645644\n",
      "train loss:1.9595457315529585\n",
      "train loss:1.940198405209351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:113, train acc:0.39666666666666667, test acc:0.3302 ===\n",
      "train loss:2.0174568863128504\n",
      "train loss:2.0356795584419753\n",
      "train loss:2.0803340910583072\n",
      "=== epoch:114, train acc:0.4033333333333333, test acc:0.3351 ===\n",
      "train loss:2.011349502019848\n",
      "train loss:2.018937144616902\n",
      "train loss:2.0326310504458216\n",
      "=== epoch:115, train acc:0.41, test acc:0.3389 ===\n",
      "train loss:2.047328225197366\n",
      "train loss:2.000564268287219\n",
      "train loss:1.9986456152395076\n",
      "=== epoch:116, train acc:0.4166666666666667, test acc:0.3392 ===\n",
      "train loss:2.0353856971909066\n",
      "train loss:1.9617442809447323\n",
      "train loss:1.9730737682639283\n",
      "=== epoch:117, train acc:0.4066666666666667, test acc:0.3391 ===\n",
      "train loss:2.0811904999603286\n",
      "train loss:1.9982454148194202\n",
      "train loss:1.9099551853421044\n",
      "=== epoch:118, train acc:0.4033333333333333, test acc:0.3353 ===\n",
      "train loss:2.038119534073546\n",
      "train loss:2.0336024471390846\n",
      "train loss:2.0772688778851127\n",
      "=== epoch:119, train acc:0.4066666666666667, test acc:0.341 ===\n",
      "train loss:2.012883234390992\n",
      "train loss:1.991266241357442\n",
      "train loss:1.9965751567913068\n",
      "=== epoch:120, train acc:0.4166666666666667, test acc:0.3427 ===\n",
      "train loss:2.0559529167706243\n",
      "train loss:1.95775722205489\n",
      "train loss:2.002138254838518\n",
      "=== epoch:121, train acc:0.43, test acc:0.3471 ===\n",
      "train loss:1.9810044860570397\n",
      "train loss:1.9472661196808188\n",
      "train loss:1.960462603989779\n",
      "=== epoch:122, train acc:0.4266666666666667, test acc:0.3467 ===\n",
      "train loss:1.9800986330452668\n",
      "train loss:2.006500868591071\n",
      "train loss:1.941304355075619\n",
      "=== epoch:123, train acc:0.43333333333333335, test acc:0.3506 ===\n",
      "train loss:1.9786708350620918\n",
      "train loss:1.9429822490781095\n",
      "train loss:1.9510549180636556\n",
      "=== epoch:124, train acc:0.43333333333333335, test acc:0.3521 ===\n",
      "train loss:1.9159562949843008\n",
      "train loss:1.935175477783923\n",
      "train loss:1.9214938369958832\n",
      "=== epoch:125, train acc:0.43333333333333335, test acc:0.3502 ===\n",
      "train loss:1.9666572690291482\n",
      "train loss:1.997926100213039\n",
      "train loss:1.9924729408018096\n",
      "=== epoch:126, train acc:0.44333333333333336, test acc:0.3569 ===\n",
      "train loss:1.9431111377951606\n",
      "train loss:1.8962948468134184\n",
      "train loss:1.9821110844665193\n",
      "=== epoch:127, train acc:0.45, test acc:0.3599 ===\n",
      "train loss:1.938735475358916\n",
      "train loss:1.9760869462458248\n",
      "train loss:1.9691862458978833\n",
      "=== epoch:128, train acc:0.45666666666666667, test acc:0.3634 ===\n",
      "train loss:1.9498722884532078\n",
      "train loss:1.9788541305415268\n",
      "train loss:1.9146004966207124\n",
      "=== epoch:129, train acc:0.4533333333333333, test acc:0.3645 ===\n",
      "train loss:1.9923835682111564\n",
      "train loss:1.8869363662172993\n",
      "train loss:1.9479654574157033\n",
      "=== epoch:130, train acc:0.47, test acc:0.3672 ===\n",
      "train loss:1.9429314148947856\n",
      "train loss:1.9261682762447145\n",
      "train loss:1.885405790846486\n",
      "=== epoch:131, train acc:0.4633333333333333, test acc:0.3637 ===\n",
      "train loss:1.8660722849228784\n",
      "train loss:1.841304477052978\n",
      "train loss:1.8705087560558682\n",
      "=== epoch:132, train acc:0.45666666666666667, test acc:0.3607 ===\n",
      "train loss:1.9089539903041828\n",
      "train loss:1.9130222011661784\n",
      "train loss:1.9641188167163934\n",
      "=== epoch:133, train acc:0.4666666666666667, test acc:0.3655 ===\n",
      "train loss:1.9025853340303374\n",
      "train loss:1.8678812199116066\n",
      "train loss:1.8663158634347679\n",
      "=== epoch:134, train acc:0.4666666666666667, test acc:0.3659 ===\n",
      "train loss:1.8604156429752137\n",
      "train loss:1.9253014096505612\n",
      "train loss:1.8776577267757342\n",
      "=== epoch:135, train acc:0.4666666666666667, test acc:0.3661 ===\n",
      "train loss:1.8523445614995497\n",
      "train loss:1.8981344738505268\n",
      "train loss:1.8927053331630619\n",
      "=== epoch:136, train acc:0.4666666666666667, test acc:0.3669 ===\n",
      "train loss:1.9344218826155253\n",
      "train loss:1.8300815033224174\n",
      "train loss:1.9141126363541952\n",
      "=== epoch:137, train acc:0.47, test acc:0.3682 ===\n",
      "train loss:1.855409489211735\n",
      "train loss:1.9519176789402846\n",
      "train loss:1.881342804317636\n",
      "=== epoch:138, train acc:0.47, test acc:0.3704 ===\n",
      "train loss:1.8950143227572889\n",
      "train loss:1.941256157516709\n",
      "train loss:1.8905547087747805\n",
      "=== epoch:139, train acc:0.47, test acc:0.3721 ===\n",
      "train loss:1.8178850272701683\n",
      "train loss:1.9485087417750884\n",
      "train loss:1.809835930373234\n",
      "=== epoch:140, train acc:0.47, test acc:0.3719 ===\n",
      "train loss:1.8477540386251607\n",
      "train loss:1.9185818700832222\n",
      "train loss:1.931817203335879\n",
      "=== epoch:141, train acc:0.4666666666666667, test acc:0.3717 ===\n",
      "train loss:1.8932263183587141\n",
      "train loss:1.8576438914679299\n",
      "train loss:1.8800255484884771\n",
      "=== epoch:142, train acc:0.47333333333333333, test acc:0.3728 ===\n",
      "train loss:1.8683894373675627\n",
      "train loss:1.8835466378044443\n",
      "train loss:1.7892462951929855\n",
      "=== epoch:143, train acc:0.47, test acc:0.3729 ===\n",
      "train loss:1.9764099602283167\n",
      "train loss:1.9083297934706422\n",
      "train loss:1.8964121235821394\n",
      "=== epoch:144, train acc:0.47, test acc:0.3758 ===\n",
      "train loss:1.851829872280521\n",
      "train loss:1.8283265257744192\n",
      "train loss:1.8529505170080045\n",
      "=== epoch:145, train acc:0.4666666666666667, test acc:0.376 ===\n",
      "train loss:1.791325375273993\n",
      "train loss:1.846320701454981\n",
      "train loss:1.8186633909302137\n",
      "=== epoch:146, train acc:0.47, test acc:0.3768 ===\n",
      "train loss:1.8445011873951938\n",
      "train loss:1.823657033273113\n",
      "train loss:1.8369129435534555\n",
      "=== epoch:147, train acc:0.47, test acc:0.3773 ===\n",
      "train loss:1.853308566915945\n",
      "train loss:1.8570298017338018\n",
      "train loss:1.8089700982074453\n",
      "=== epoch:148, train acc:0.47333333333333333, test acc:0.3791 ===\n",
      "train loss:1.8668798198299088\n",
      "train loss:1.900946514384346\n",
      "train loss:1.888522709408607\n",
      "=== epoch:149, train acc:0.47, test acc:0.3821 ===\n",
      "train loss:1.83134602585835\n",
      "train loss:1.847213831094055\n",
      "train loss:1.7354569217688658\n",
      "=== epoch:150, train acc:0.47333333333333333, test acc:0.3827 ===\n",
      "train loss:1.8209268193637018\n",
      "train loss:1.8919756088745787\n",
      "train loss:1.8918760162589654\n",
      "=== epoch:151, train acc:0.4766666666666667, test acc:0.3863 ===\n",
      "train loss:1.8000328218474086\n",
      "train loss:1.852573240115256\n",
      "train loss:1.7809269894969149\n",
      "=== epoch:152, train acc:0.4766666666666667, test acc:0.3852 ===\n",
      "train loss:1.781790292732077\n",
      "train loss:1.8960700946643876\n",
      "train loss:1.8884385192637339\n",
      "=== epoch:153, train acc:0.4766666666666667, test acc:0.3869 ===\n",
      "train loss:1.7503981909774478\n",
      "train loss:1.8483682067278113\n",
      "train loss:1.8267642648206075\n",
      "=== epoch:154, train acc:0.48, test acc:0.3866 ===\n",
      "train loss:1.7986879616258185\n",
      "train loss:1.8404588516229707\n",
      "train loss:1.741622373145678\n",
      "=== epoch:155, train acc:0.48, test acc:0.3864 ===\n",
      "train loss:1.8298979534748587\n",
      "train loss:1.7855322324493885\n",
      "train loss:1.829492263050771\n",
      "=== epoch:156, train acc:0.48333333333333334, test acc:0.3905 ===\n",
      "train loss:1.7905405443708653\n",
      "train loss:1.7784642073171295\n",
      "train loss:1.7299936071834643\n",
      "=== epoch:157, train acc:0.49333333333333335, test acc:0.3902 ===\n",
      "train loss:1.6916686026440464\n",
      "train loss:1.746723721404426\n",
      "train loss:1.8409108096888016\n",
      "=== epoch:158, train acc:0.49333333333333335, test acc:0.3947 ===\n",
      "train loss:1.7516596725113214\n",
      "train loss:1.745859119128854\n",
      "train loss:1.8289032164384402\n",
      "=== epoch:159, train acc:0.49333333333333335, test acc:0.396 ===\n",
      "train loss:1.7817013550726286\n",
      "train loss:1.8138603426195012\n",
      "train loss:1.8211702071925198\n",
      "=== epoch:160, train acc:0.49333333333333335, test acc:0.3964 ===\n",
      "train loss:1.7975070696143447\n",
      "train loss:1.8238594807492001\n",
      "train loss:1.717233524144709\n",
      "=== epoch:161, train acc:0.49666666666666665, test acc:0.398 ===\n",
      "train loss:1.810471957870796\n",
      "train loss:1.660662696911482\n",
      "train loss:1.7667044242078678\n",
      "=== epoch:162, train acc:0.5033333333333333, test acc:0.4001 ===\n",
      "train loss:1.8141288205032753\n",
      "train loss:1.704830125581396\n",
      "train loss:1.7701753255656405\n",
      "=== epoch:163, train acc:0.49666666666666665, test acc:0.4016 ===\n",
      "train loss:1.7907024039159052\n",
      "train loss:1.7007446750996513\n",
      "train loss:1.7252179103891137\n",
      "=== epoch:164, train acc:0.5, test acc:0.4017 ===\n",
      "train loss:1.739909754832284\n",
      "train loss:1.773612607925232\n",
      "train loss:1.586917652534009\n",
      "=== epoch:165, train acc:0.5066666666666667, test acc:0.4041 ===\n",
      "train loss:1.7815104764084242\n",
      "train loss:1.6878941360658708\n",
      "train loss:1.7916014736314179\n",
      "=== epoch:166, train acc:0.5166666666666667, test acc:0.4069 ===\n",
      "train loss:1.65500719813891\n",
      "train loss:1.6722614375552753\n",
      "train loss:1.7042726949140485\n",
      "=== epoch:167, train acc:0.5133333333333333, test acc:0.4072 ===\n",
      "train loss:1.6801400356667713\n",
      "train loss:1.727657673068417\n",
      "train loss:1.8102392653238548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:168, train acc:0.52, test acc:0.4057 ===\n",
      "train loss:1.8003172265230674\n",
      "train loss:1.6815483025488365\n",
      "train loss:1.6735996692510475\n",
      "=== epoch:169, train acc:0.5133333333333333, test acc:0.4054 ===\n",
      "train loss:1.7139808928372482\n",
      "train loss:1.6806684685467657\n",
      "train loss:1.5725720234132057\n",
      "=== epoch:170, train acc:0.52, test acc:0.4071 ===\n",
      "train loss:1.6369675505039851\n",
      "train loss:1.710309129842666\n",
      "train loss:1.6567477135311115\n",
      "=== epoch:171, train acc:0.5233333333333333, test acc:0.4107 ===\n",
      "train loss:1.6622682870175587\n",
      "train loss:1.7759498797837028\n",
      "train loss:1.718624040327122\n",
      "=== epoch:172, train acc:0.5266666666666666, test acc:0.4121 ===\n",
      "train loss:1.6670827730453175\n",
      "train loss:1.6568479156071407\n",
      "train loss:1.6866081055390252\n",
      "=== epoch:173, train acc:0.5233333333333333, test acc:0.4162 ===\n",
      "train loss:1.6254421433293542\n",
      "train loss:1.7294116883201434\n",
      "train loss:1.7017453618407663\n",
      "=== epoch:174, train acc:0.5333333333333333, test acc:0.4168 ===\n",
      "train loss:1.6394201375747877\n",
      "train loss:1.6160520111825596\n",
      "train loss:1.6830821493188446\n",
      "=== epoch:175, train acc:0.5333333333333333, test acc:0.4159 ===\n",
      "train loss:1.6381481411049053\n",
      "train loss:1.6966606890298133\n",
      "train loss:1.5436297177433231\n",
      "=== epoch:176, train acc:0.54, test acc:0.4189 ===\n",
      "train loss:1.6375952226203285\n",
      "train loss:1.677865368151175\n",
      "train loss:1.6712223078794777\n",
      "=== epoch:177, train acc:0.5466666666666666, test acc:0.422 ===\n",
      "train loss:1.6371134880213676\n",
      "train loss:1.6732460888705496\n",
      "train loss:1.673004274079294\n",
      "=== epoch:178, train acc:0.55, test acc:0.4275 ===\n",
      "train loss:1.592852578693743\n",
      "train loss:1.56066780376171\n",
      "train loss:1.6708837825835423\n",
      "=== epoch:179, train acc:0.5533333333333333, test acc:0.4307 ===\n",
      "train loss:1.6409815576729014\n",
      "train loss:1.6368647063065993\n",
      "train loss:1.6867866855569245\n",
      "=== epoch:180, train acc:0.55, test acc:0.4321 ===\n",
      "train loss:1.5955404782590024\n",
      "train loss:1.558617033386226\n",
      "train loss:1.6041718628009787\n",
      "=== epoch:181, train acc:0.5533333333333333, test acc:0.435 ===\n",
      "train loss:1.5626275043956699\n",
      "train loss:1.6609719678939965\n",
      "train loss:1.569963408686325\n",
      "=== epoch:182, train acc:0.55, test acc:0.4395 ===\n",
      "train loss:1.6549500800138872\n",
      "train loss:1.5334551458548136\n",
      "train loss:1.5540876285366785\n",
      "=== epoch:183, train acc:0.5566666666666666, test acc:0.4385 ===\n",
      "train loss:1.6020080091548945\n",
      "train loss:1.6396264196326078\n",
      "train loss:1.5392574343220453\n",
      "=== epoch:184, train acc:0.56, test acc:0.439 ===\n",
      "train loss:1.4994571646815564\n",
      "train loss:1.5508301205927302\n",
      "train loss:1.5495560435579867\n",
      "=== epoch:185, train acc:0.5566666666666666, test acc:0.4354 ===\n",
      "train loss:1.5675350952725233\n",
      "train loss:1.5182348008129798\n",
      "train loss:1.542613485792819\n",
      "=== epoch:186, train acc:0.55, test acc:0.4366 ===\n",
      "train loss:1.4504207544007792\n",
      "train loss:1.6121393892082307\n",
      "train loss:1.511399073051015\n",
      "=== epoch:187, train acc:0.55, test acc:0.4358 ===\n",
      "train loss:1.5002174263051808\n",
      "train loss:1.4936206081225298\n",
      "train loss:1.493084860773653\n",
      "=== epoch:188, train acc:0.55, test acc:0.4374 ===\n",
      "train loss:1.4373650561886877\n",
      "train loss:1.4298074374777971\n",
      "train loss:1.6057497972204329\n",
      "=== epoch:189, train acc:0.55, test acc:0.4389 ===\n",
      "train loss:1.560988982217651\n",
      "train loss:1.4594458692981547\n",
      "train loss:1.4477224539558546\n",
      "=== epoch:190, train acc:0.55, test acc:0.4383 ===\n",
      "train loss:1.5400040117241085\n",
      "train loss:1.5351597746996606\n",
      "train loss:1.5329467369941094\n",
      "=== epoch:191, train acc:0.55, test acc:0.439 ===\n",
      "train loss:1.5338993566370795\n",
      "train loss:1.526483320996132\n",
      "train loss:1.4563526447688708\n",
      "=== epoch:192, train acc:0.5533333333333333, test acc:0.4361 ===\n",
      "train loss:1.5087011813425832\n",
      "train loss:1.491394978076198\n",
      "train loss:1.5052231956659083\n",
      "=== epoch:193, train acc:0.5533333333333333, test acc:0.4355 ===\n",
      "train loss:1.54271818943141\n",
      "train loss:1.5084980650124107\n",
      "train loss:1.5548162179839968\n",
      "=== epoch:194, train acc:0.55, test acc:0.4373 ===\n",
      "train loss:1.456700735769021\n",
      "train loss:1.5464745692518305\n",
      "train loss:1.489678467079286\n",
      "=== epoch:195, train acc:0.5533333333333333, test acc:0.4398 ===\n",
      "train loss:1.5803426428695695\n",
      "train loss:1.5379581635618933\n",
      "train loss:1.5698697781547681\n",
      "=== epoch:196, train acc:0.5533333333333333, test acc:0.4448 ===\n",
      "train loss:1.4732453590328054\n",
      "train loss:1.5445054289277431\n",
      "train loss:1.5030073326992899\n",
      "=== epoch:197, train acc:0.5666666666666667, test acc:0.4521 ===\n",
      "train loss:1.5979576260111816\n",
      "train loss:1.4029043667466408\n",
      "train loss:1.5596029675878862\n",
      "=== epoch:198, train acc:0.5633333333333334, test acc:0.4536 ===\n",
      "train loss:1.4087130152293934\n",
      "train loss:1.4094204299872073\n",
      "train loss:1.3870526473380587\n",
      "=== epoch:199, train acc:0.5666666666666667, test acc:0.4534 ===\n",
      "train loss:1.3147914440004498\n",
      "train loss:1.4391032679351665\n",
      "train loss:1.532851486604101\n",
      "=== epoch:200, train acc:0.5666666666666667, test acc:0.4533 ===\n",
      "train loss:1.3903639669114742\n",
      "train loss:1.421468568946421\n",
      "train loss:1.4079246809855201\n",
      "=== epoch:201, train acc:0.57, test acc:0.4504 ===\n",
      "train loss:1.5110616544058302\n",
      "train loss:1.4498441927698165\n",
      "train loss:1.4541244964980848\n",
      "=== epoch:202, train acc:0.57, test acc:0.4523 ===\n",
      "train loss:1.3843132243789313\n",
      "train loss:1.4713573858116888\n",
      "train loss:1.393141063670953\n",
      "=== epoch:203, train acc:0.5666666666666667, test acc:0.4522 ===\n",
      "train loss:1.4842826173493306\n",
      "train loss:1.3616631850417706\n",
      "train loss:1.509979556211571\n",
      "=== epoch:204, train acc:0.57, test acc:0.4575 ===\n",
      "train loss:1.4010672441032777\n",
      "train loss:1.3253012262142188\n",
      "train loss:1.5035142303175157\n",
      "=== epoch:205, train acc:0.5733333333333334, test acc:0.4528 ===\n",
      "train loss:1.3883511704476663\n",
      "train loss:1.41777278848912\n",
      "train loss:1.4690627271477572\n",
      "=== epoch:206, train acc:0.57, test acc:0.4548 ===\n",
      "train loss:1.3482171846643698\n",
      "train loss:1.3530835072506862\n",
      "train loss:1.4192574326540075\n",
      "=== epoch:207, train acc:0.57, test acc:0.4544 ===\n",
      "train loss:1.4061452752334438\n",
      "train loss:1.3094514739211593\n",
      "train loss:1.4537757937352873\n",
      "=== epoch:208, train acc:0.5766666666666667, test acc:0.4605 ===\n",
      "train loss:1.4646434316286052\n",
      "train loss:1.3537356171522614\n",
      "train loss:1.3007146135276075\n",
      "=== epoch:209, train acc:0.5766666666666667, test acc:0.4628 ===\n",
      "train loss:1.3003182723392146\n",
      "train loss:1.3067735551545385\n",
      "train loss:1.3512778189104266\n",
      "=== epoch:210, train acc:0.5733333333333334, test acc:0.4581 ===\n",
      "train loss:1.2473901062770545\n",
      "train loss:1.3418459479123794\n",
      "train loss:1.3714842284378421\n",
      "=== epoch:211, train acc:0.5866666666666667, test acc:0.4649 ===\n",
      "train loss:1.3076200622685061\n",
      "train loss:1.3592934202401028\n",
      "train loss:1.43238434543534\n",
      "=== epoch:212, train acc:0.58, test acc:0.4677 ===\n",
      "train loss:1.3471035280929586\n",
      "train loss:1.4929478715552456\n",
      "train loss:1.3890227729826867\n",
      "=== epoch:213, train acc:0.58, test acc:0.4715 ===\n",
      "train loss:1.349413096887385\n",
      "train loss:1.3359654528309728\n",
      "train loss:1.3526990950952091\n",
      "=== epoch:214, train acc:0.58, test acc:0.4716 ===\n",
      "train loss:1.2663299936528203\n",
      "train loss:1.2936688779565475\n",
      "train loss:1.5100251208722213\n",
      "=== epoch:215, train acc:0.6, test acc:0.4768 ===\n",
      "train loss:1.2202800999059469\n",
      "train loss:1.222214404993553\n",
      "train loss:1.3760278815021885\n",
      "=== epoch:216, train acc:0.6, test acc:0.4717 ===\n",
      "train loss:1.39478925720007\n",
      "train loss:1.3120394861825226\n",
      "train loss:1.3194868739962087\n",
      "=== epoch:217, train acc:0.5933333333333334, test acc:0.4735 ===\n",
      "train loss:1.2718374911997605\n",
      "train loss:1.4007868099701606\n",
      "train loss:1.3203296281457515\n",
      "=== epoch:218, train acc:0.59, test acc:0.4761 ===\n",
      "train loss:1.2941596527769357\n",
      "train loss:1.3295228669531514\n",
      "train loss:1.3877144646587354\n",
      "=== epoch:219, train acc:0.5866666666666667, test acc:0.4742 ===\n",
      "train loss:1.2471679503926376\n",
      "train loss:1.3770834955447722\n",
      "train loss:1.2931281062420583\n",
      "=== epoch:220, train acc:0.6066666666666667, test acc:0.4817 ===\n",
      "train loss:1.3676446545527141\n",
      "train loss:1.374354639686822\n",
      "train loss:1.3950020255557822\n",
      "=== epoch:221, train acc:0.5966666666666667, test acc:0.4766 ===\n",
      "train loss:1.3004514731973884\n",
      "train loss:1.2418860859317733\n",
      "train loss:1.3541415664900975\n",
      "=== epoch:222, train acc:0.5966666666666667, test acc:0.4801 ===\n",
      "train loss:1.3692642048689132\n",
      "train loss:1.2896654796965898\n",
      "train loss:1.3062127211271706\n",
      "=== epoch:223, train acc:0.6033333333333334, test acc:0.4849 ===\n",
      "train loss:1.374043070064979\n",
      "train loss:1.238793811678131\n",
      "train loss:1.3616938861007413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:224, train acc:0.6033333333333334, test acc:0.4841 ===\n",
      "train loss:1.260534067452019\n",
      "train loss:1.3072570249325093\n",
      "train loss:1.2039441132786872\n",
      "=== epoch:225, train acc:0.6066666666666667, test acc:0.48 ===\n",
      "train loss:1.3115046390432423\n",
      "train loss:1.2328004046555459\n",
      "train loss:1.197269355913586\n",
      "=== epoch:226, train acc:0.6133333333333333, test acc:0.482 ===\n",
      "train loss:1.3028992969701787\n",
      "train loss:1.3848512261452997\n",
      "train loss:1.346403689089225\n",
      "=== epoch:227, train acc:0.6133333333333333, test acc:0.4867 ===\n",
      "train loss:1.2894764138583235\n",
      "train loss:1.2489315096847553\n",
      "train loss:1.1456019039847485\n",
      "=== epoch:228, train acc:0.61, test acc:0.4885 ===\n",
      "train loss:1.254796383711233\n",
      "train loss:1.2716447601013807\n",
      "train loss:1.3011615873467413\n",
      "=== epoch:229, train acc:0.6133333333333333, test acc:0.4907 ===\n",
      "train loss:1.2749173653056787\n",
      "train loss:1.4210568036503546\n",
      "train loss:1.2900441982752366\n",
      "=== epoch:230, train acc:0.63, test acc:0.4968 ===\n",
      "train loss:1.195837920272514\n",
      "train loss:1.2117079666916741\n",
      "train loss:1.457458820244702\n",
      "=== epoch:231, train acc:0.6233333333333333, test acc:0.4952 ===\n",
      "train loss:1.2574907523081553\n",
      "train loss:1.282568412346147\n",
      "train loss:1.293559527654269\n",
      "=== epoch:232, train acc:0.6266666666666667, test acc:0.4991 ===\n",
      "train loss:1.233015166840923\n",
      "train loss:1.4535190809845018\n",
      "train loss:1.2594524611676439\n",
      "=== epoch:233, train acc:0.6366666666666667, test acc:0.5075 ===\n",
      "train loss:1.2476987220660543\n",
      "train loss:1.2427421140989212\n",
      "train loss:1.3437623910278402\n",
      "=== epoch:234, train acc:0.6366666666666667, test acc:0.5108 ===\n",
      "train loss:1.095602263996378\n",
      "train loss:1.1979343705609369\n",
      "train loss:1.2278729930651209\n",
      "=== epoch:235, train acc:0.6366666666666667, test acc:0.5077 ===\n",
      "train loss:1.1371789013271674\n",
      "train loss:1.1899887973954093\n",
      "train loss:1.1919098166060207\n",
      "=== epoch:236, train acc:0.6366666666666667, test acc:0.5063 ===\n",
      "train loss:1.3066855366103598\n",
      "train loss:1.2064687009396189\n",
      "train loss:1.1720156879172243\n",
      "=== epoch:237, train acc:0.64, test acc:0.5037 ===\n",
      "train loss:1.231375086527745\n",
      "train loss:1.2877578523594808\n",
      "train loss:1.091777422119771\n",
      "=== epoch:238, train acc:0.64, test acc:0.5078 ===\n",
      "train loss:1.3177954162169525\n",
      "train loss:1.2575108176871879\n",
      "train loss:1.228910924407063\n",
      "=== epoch:239, train acc:0.64, test acc:0.5088 ===\n",
      "train loss:1.2027349073872986\n",
      "train loss:1.1575285793018644\n",
      "train loss:1.399196226169107\n",
      "=== epoch:240, train acc:0.6466666666666666, test acc:0.5094 ===\n",
      "train loss:1.2935683640342037\n",
      "train loss:1.254723047856344\n",
      "train loss:1.2494133955627715\n",
      "=== epoch:241, train acc:0.6433333333333333, test acc:0.511 ===\n",
      "train loss:1.0907807774161427\n",
      "train loss:1.1989644910828898\n",
      "train loss:1.1761913405080837\n",
      "=== epoch:242, train acc:0.6533333333333333, test acc:0.5139 ===\n",
      "train loss:1.1108835618064352\n",
      "train loss:1.2121488442138886\n",
      "train loss:1.2714088221165212\n",
      "=== epoch:243, train acc:0.6466666666666666, test acc:0.5139 ===\n",
      "train loss:1.1693047067072235\n",
      "train loss:1.1236488116505947\n",
      "train loss:1.1816672084013964\n",
      "=== epoch:244, train acc:0.6433333333333333, test acc:0.5091 ===\n",
      "train loss:1.0508224892603948\n",
      "train loss:1.1573366804496719\n",
      "train loss:1.1197202621498783\n",
      "=== epoch:245, train acc:0.6533333333333333, test acc:0.508 ===\n",
      "train loss:1.3286387123172068\n",
      "train loss:1.2454726386255548\n",
      "train loss:1.1736272883385235\n",
      "=== epoch:246, train acc:0.65, test acc:0.5116 ===\n",
      "train loss:1.1662695179489588\n",
      "train loss:1.1114858041157893\n",
      "train loss:1.1139169363944843\n",
      "=== epoch:247, train acc:0.64, test acc:0.5081 ===\n",
      "train loss:1.1600988942969546\n",
      "train loss:1.2625278208081996\n",
      "train loss:1.202908900350988\n",
      "=== epoch:248, train acc:0.6466666666666666, test acc:0.5089 ===\n",
      "train loss:1.2236973213109088\n",
      "train loss:1.1593621011040542\n",
      "train loss:1.1690014106789324\n",
      "=== epoch:249, train acc:0.6466666666666666, test acc:0.515 ===\n",
      "train loss:1.1771201965338498\n",
      "train loss:1.1891175455635363\n",
      "train loss:1.0245408875362891\n",
      "=== epoch:250, train acc:0.6533333333333333, test acc:0.5089 ===\n",
      "train loss:1.2133404647875157\n",
      "train loss:1.2021050877965822\n",
      "train loss:1.1910636698019632\n",
      "=== epoch:251, train acc:0.6566666666666666, test acc:0.5124 ===\n",
      "train loss:1.148459521817646\n",
      "train loss:1.1357719127581238\n",
      "train loss:1.1670520213576092\n",
      "=== epoch:252, train acc:0.6533333333333333, test acc:0.513 ===\n",
      "train loss:1.1794194402229574\n",
      "train loss:1.189966513051008\n",
      "train loss:1.1692162474139438\n",
      "=== epoch:253, train acc:0.66, test acc:0.5127 ===\n",
      "train loss:1.1949974966295165\n",
      "train loss:1.0750727423748194\n",
      "train loss:1.0521645968086026\n",
      "=== epoch:254, train acc:0.6466666666666666, test acc:0.5066 ===\n",
      "train loss:1.1019292912513516\n",
      "train loss:1.1378717069633146\n",
      "train loss:1.131462138757234\n",
      "=== epoch:255, train acc:0.64, test acc:0.5063 ===\n",
      "train loss:1.262800665983484\n",
      "train loss:1.015289795376863\n",
      "train loss:1.1665843015559738\n",
      "=== epoch:256, train acc:0.64, test acc:0.5103 ===\n",
      "train loss:0.9729363508683576\n",
      "train loss:1.1445193515034726\n",
      "train loss:1.2065006529606832\n",
      "=== epoch:257, train acc:0.6466666666666666, test acc:0.5129 ===\n",
      "train loss:1.0192635637026486\n",
      "train loss:1.1566808361272896\n",
      "train loss:1.0241568068683673\n",
      "=== epoch:258, train acc:0.6533333333333333, test acc:0.5159 ===\n",
      "train loss:1.0401650808896208\n",
      "train loss:0.9330412572885378\n",
      "train loss:1.1554035208723537\n",
      "=== epoch:259, train acc:0.6366666666666667, test acc:0.5066 ===\n",
      "train loss:1.1660566609418435\n",
      "train loss:1.1122984996150058\n",
      "train loss:1.055065776543045\n",
      "=== epoch:260, train acc:0.6433333333333333, test acc:0.508 ===\n",
      "train loss:1.0158447667557204\n",
      "train loss:1.0566038559276194\n",
      "train loss:1.2041465346841613\n",
      "=== epoch:261, train acc:0.65, test acc:0.5106 ===\n",
      "train loss:1.202500061547716\n",
      "train loss:1.2542927694633006\n",
      "train loss:1.109148949821475\n",
      "=== epoch:262, train acc:0.6566666666666666, test acc:0.5125 ===\n",
      "train loss:1.1121666253223659\n",
      "train loss:1.0932657232575351\n",
      "train loss:1.0800212615484197\n",
      "=== epoch:263, train acc:0.66, test acc:0.5158 ===\n",
      "train loss:1.0890336649625745\n",
      "train loss:0.9916657536426935\n",
      "train loss:1.0036386742337244\n",
      "=== epoch:264, train acc:0.6533333333333333, test acc:0.5144 ===\n",
      "train loss:1.0188880506958873\n",
      "train loss:1.1881604558779215\n",
      "train loss:1.1385321199929617\n",
      "=== epoch:265, train acc:0.66, test acc:0.5172 ===\n",
      "train loss:1.1032739136011434\n",
      "train loss:1.0304334074911474\n",
      "train loss:1.0940177907369033\n",
      "=== epoch:266, train acc:0.6533333333333333, test acc:0.515 ===\n",
      "train loss:1.0430597394562569\n",
      "train loss:1.1274898897440462\n",
      "train loss:1.0859725677851244\n",
      "=== epoch:267, train acc:0.66, test acc:0.5164 ===\n",
      "train loss:1.1317132046394207\n",
      "train loss:0.989116469186166\n",
      "train loss:1.0746094939629487\n",
      "=== epoch:268, train acc:0.66, test acc:0.5227 ===\n",
      "train loss:1.0565595199078612\n",
      "train loss:0.9463487720323006\n",
      "train loss:1.0094609281109266\n",
      "=== epoch:269, train acc:0.6466666666666666, test acc:0.5195 ===\n",
      "train loss:1.017205429661044\n",
      "train loss:1.0866841411230155\n",
      "train loss:1.063577040769105\n",
      "=== epoch:270, train acc:0.6633333333333333, test acc:0.522 ===\n",
      "train loss:1.0668054998375958\n",
      "train loss:1.0826764662865407\n",
      "train loss:0.9370803329802437\n",
      "=== epoch:271, train acc:0.6566666666666666, test acc:0.5238 ===\n",
      "train loss:1.086821146885202\n",
      "train loss:0.9996172759851776\n",
      "train loss:1.085580304682145\n",
      "=== epoch:272, train acc:0.6666666666666666, test acc:0.5226 ===\n",
      "train loss:1.0702743992623722\n",
      "train loss:1.152775625123907\n",
      "train loss:1.0677926494583372\n",
      "=== epoch:273, train acc:0.6666666666666666, test acc:0.5274 ===\n",
      "train loss:1.0155823135254398\n",
      "train loss:1.0206944701270961\n",
      "train loss:1.0519121282108224\n",
      "=== epoch:274, train acc:0.67, test acc:0.5275 ===\n",
      "train loss:0.8767246245052303\n",
      "train loss:1.1820523150156304\n",
      "train loss:1.1098533991623005\n",
      "=== epoch:275, train acc:0.6733333333333333, test acc:0.5321 ===\n",
      "train loss:1.0367520116702655\n",
      "train loss:1.019157118762978\n",
      "train loss:0.9878361062913403\n",
      "=== epoch:276, train acc:0.6766666666666666, test acc:0.5312 ===\n",
      "train loss:1.0471945986480111\n",
      "train loss:1.1207286895871333\n",
      "train loss:0.9963151831752018\n",
      "=== epoch:277, train acc:0.69, test acc:0.5362 ===\n",
      "train loss:1.0027996813492432\n",
      "train loss:1.0485695303582243\n",
      "train loss:1.0624542680335003\n",
      "=== epoch:278, train acc:0.6866666666666666, test acc:0.537 ===\n",
      "train loss:1.0193851391814628\n",
      "train loss:0.9404140754270024\n",
      "train loss:1.137499358206054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:279, train acc:0.6933333333333334, test acc:0.5354 ===\n",
      "train loss:1.086554760445063\n",
      "train loss:0.9647415055753445\n",
      "train loss:0.9400381887457228\n",
      "=== epoch:280, train acc:0.6866666666666666, test acc:0.536 ===\n",
      "train loss:1.0233592879785156\n",
      "train loss:0.9806431969607542\n",
      "train loss:1.0381082824801733\n",
      "=== epoch:281, train acc:0.69, test acc:0.5392 ===\n",
      "train loss:1.0502998423690673\n",
      "train loss:1.0828810307089956\n",
      "train loss:1.0022427706995731\n",
      "=== epoch:282, train acc:0.69, test acc:0.5408 ===\n",
      "train loss:1.072790581058976\n",
      "train loss:0.9875106192083267\n",
      "train loss:1.012049338407988\n",
      "=== epoch:283, train acc:0.69, test acc:0.5395 ===\n",
      "train loss:0.9571941344955996\n",
      "train loss:0.9550036301161553\n",
      "train loss:1.058107230751862\n",
      "=== epoch:284, train acc:0.6866666666666666, test acc:0.5335 ===\n",
      "train loss:1.1841149357086622\n",
      "train loss:0.851664332210331\n",
      "train loss:0.966547979457679\n",
      "=== epoch:285, train acc:0.6766666666666666, test acc:0.5308 ===\n",
      "train loss:1.0218512541679767\n",
      "train loss:1.0082546056356245\n",
      "train loss:1.0089823275848948\n",
      "=== epoch:286, train acc:0.68, test acc:0.5317 ===\n",
      "train loss:1.1021777328129962\n",
      "train loss:1.044520428076212\n",
      "train loss:0.8845531716397805\n",
      "=== epoch:287, train acc:0.6933333333333334, test acc:0.5346 ===\n",
      "train loss:1.0423211303673003\n",
      "train loss:1.0632383754420198\n",
      "train loss:0.914554596906288\n",
      "=== epoch:288, train acc:0.6833333333333333, test acc:0.536 ===\n",
      "train loss:0.9598273589749879\n",
      "train loss:0.8968823622065785\n",
      "train loss:1.0810049188723798\n",
      "=== epoch:289, train acc:0.6766666666666666, test acc:0.5322 ===\n",
      "train loss:0.9965603121539158\n",
      "train loss:1.0481414142184107\n",
      "train loss:1.0103071767051521\n",
      "=== epoch:290, train acc:0.6766666666666666, test acc:0.5322 ===\n",
      "train loss:0.8125257792852942\n",
      "train loss:1.0113335723351193\n",
      "train loss:1.0486638452853987\n",
      "=== epoch:291, train acc:0.69, test acc:0.5361 ===\n",
      "train loss:0.9218886929789605\n",
      "train loss:1.056124406087099\n",
      "train loss:1.074428971868494\n",
      "=== epoch:292, train acc:0.6966666666666667, test acc:0.5376 ===\n",
      "train loss:0.9913109392681673\n",
      "train loss:0.8701235311935333\n",
      "train loss:1.0005276447492817\n",
      "=== epoch:293, train acc:0.6866666666666666, test acc:0.5352 ===\n",
      "train loss:1.0212807383927645\n",
      "train loss:0.9694301918414167\n",
      "train loss:1.0093426593828871\n",
      "=== epoch:294, train acc:0.6866666666666666, test acc:0.5352 ===\n",
      "train loss:0.9712005655523133\n",
      "train loss:0.9239321873991284\n",
      "train loss:0.9214977874952045\n",
      "=== epoch:295, train acc:0.6933333333333334, test acc:0.545 ===\n",
      "train loss:0.9781440313333105\n",
      "train loss:0.9791835728853855\n",
      "train loss:0.9433942604147307\n",
      "=== epoch:296, train acc:0.6966666666666667, test acc:0.5463 ===\n",
      "train loss:0.898861651111616\n",
      "train loss:1.0454826345537185\n",
      "train loss:1.026223614730754\n",
      "=== epoch:297, train acc:0.7133333333333334, test acc:0.5511 ===\n",
      "train loss:0.9645242780395928\n",
      "train loss:0.9789420159090987\n",
      "train loss:1.0730846053786816\n",
      "=== epoch:298, train acc:0.72, test acc:0.5529 ===\n",
      "train loss:0.9882854360058778\n",
      "train loss:0.9582622384090679\n",
      "train loss:1.1242789909685869\n",
      "=== epoch:299, train acc:0.71, test acc:0.5478 ===\n",
      "train loss:0.9329076339956424\n",
      "train loss:0.9548334952357251\n",
      "train loss:0.9440746556332371\n",
      "=== epoch:300, train acc:0.7133333333333334, test acc:0.551 ===\n",
      "train loss:0.9307975899019613\n",
      "train loss:0.9454744348513864\n",
      "train loss:0.9824983005986492\n",
      "=== epoch:301, train acc:0.7166666666666667, test acc:0.5564 ===\n",
      "train loss:0.9469697241241646\n",
      "train loss:0.983300037065947\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.5593\n"
     ]
    }
   ],
   "source": [
    "# 드롭아웃 사용 유무와 비울 설정 ========================\n",
    "use_dropout = True  # 드롭아웃을 쓰지 않을 때는 False\n",
    "dropout_ratio = 0.2\n",
    "# ====================================================\n",
    "\n",
    "network = MultiLayerNetExtend(input_size=784, hidden_size_list=[100, 100, 100, 100, 100, 100],\n",
    "                              output_size=10, use_dropout=use_dropout, dropout_ration=dropout_ratio)\n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=301, mini_batch_size=100,\n",
    "                  optimizer='sgd', optimizer_param={'lr': 0.01}, verbose=True)\n",
    "trainer.train()\n",
    "\n",
    "train_acc_list, test_acc_list = trainer.train_acc_list, trainer.test_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dfc33bbb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기==========\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, marker='o', label='train', markevery=10)\n",
    "plt.plot(x, test_acc_list, marker='s', label='test', markevery=10)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop out 적용 시 정확도가 감소하긴 하지만, 훈련 데이터와 시험 데이터 간의 차이가 감소\n",
    "- Drop out은 batch 마다 뉴런을 무작위로 삭제하며 매번 다른 모델을 학습시키는 것으로 해석가능하며, 결과적으로 **앙상블학습과 유사**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
